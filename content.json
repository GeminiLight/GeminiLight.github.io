{"meta":{"title":"Gemini向光性","subtitle":"The light always goes on","description":"GeminiLight","author":"GeminiLight","url":"https://www.geminilight.cn","root":"/"},"pages":[{"title":"404","date":"2020-01-09T05:25:01.000Z","updated":"2020-11-27T07:01:44.440Z","comments":true,"path":"/404.html","permalink":"https://www.geminilight.cn/404.html","excerpt":"","text":"404 404 UH OH! 探索到了新星球 这里好荒凉啊，觉得无聊就回去哦 返回Gemini"},{"title":"","date":"2020-08-15T16:35:19.789Z","updated":"2020-08-15T16:35:19.789Z","comments":true,"path":"404/style.css","permalink":"https://www.geminilight.cn/404/style.css","excerpt":"","text":"@import url(\"https://fonts.googleapis.com/css?family=Nunito+Sans\"); /* From Bootstrap */ .container { width: 100%; height: 100%; padding-right: 15px; padding-left: 15px; margin: 0; } @media (min-width: 576px) { .container { max-width: 540px; } } @media (min-width: 768px) { .container { max-width: 720px; } } @media (min-width: 992px) { .container { max-width: 960px; } } @media (min-width: 1200px) { .container { max-width: 1140px; } } .row { display: -ms-flexbox; display: flex; -ms-flex-wrap: wrap; flex-wrap: wrap; margin-right: -15px; margin-left: -15px; } .col-md-6 { -ms-flex: 0 0 50%; flex: 0 0 50%; max-width: 50%; } .align-self-center { -ms-flex-item-align: center !important; align-self: center !important; } /* End */ :root { --blue: #0e0620; --white: #fff; --green: #2ccf6d; } html, body { height: 100%; margin: 0px; } body { display: -webkit-box; display: flex; -webkit-box-align: center; align-items: center; -webkit-box-pack: center; justify-content: center; font-family: \"Nunito Sans\"; color: var(--blue); font-size: 1em; margin: 0px; } button { font-family: \"Nunito Sans\"; } ul { list-style-type: none; -webkit-padding-start: 35px; padding-inline-start: 35px; } svg { width: 100%; visibility: hidden; } h1 { font-size: 7.5em; margin: 15px 0px; font-weight: bold; } h2 { font-weight: bold; } .hamburger-menu { position: absolute; top: 0; left: 0; padding: 35px; z-index: 2; } .hamburger-menu button { position: relative; width: 30px; height: 22px; border: none; background: none; padding: 0; cursor: pointer; } .hamburger-menu button span { position: absolute; height: 3px; background: #000; width: 100%; left: 0px; top: 0px; -webkit-transition: 0.1s ease-in; transition: 0.1s ease-in; } .hamburger-menu button span:nth-child(2) { top: 9px; } .hamburger-menu button span:nth-child(3) { top: 18px; } .hamburger-menu [data-state=\"open\"] span:first-child { -webkit-transform: rotate(45deg); transform: rotate(45deg); top: 10px; } .hamburger-menu [data-state=\"open\"] span:nth-child(2) { width: 0%; opacity: 0; } .hamburger-menu [data-state=\"open\"] span:nth-child(3) { -webkit-transform: rotate(-45deg); transform: rotate(-45deg); top: 10px; } nav { position: absolute; height: 100%; top: 0; left: 0; background: var(--green); color: var(--blue); width: 300px; z-index: 1; padding-top: 80px; -webkit-transform: translateX(-100%); transform: translateX(-100%); -webkit-transition: 0.24s cubic-bezier(0.52, 0.01, 0.8, 1); transition: 0.24s cubic-bezier(0.52, 0.01, 0.8, 1); } nav li { -webkit-transform: translateX(-5px); transform: translateX(-5px); -webkit-transition: 0.16s cubic-bezier(0.44, 0.09, 0.46, 0.84); transition: 0.16s cubic-bezier(0.44, 0.09, 0.46, 0.84); opacity: 0; } nav a { display: block; font-size: 1.75em; font-weight: bold; text-decoration: none; color: inherit; -webkit-transition: 0.24s ease-in-out; transition: 0.24s ease-in-out; } nav a:hover { text-decoration: none; color: var(--white); } nav[data-state=\"open\"] { -webkit-transform: translateX(0%); transform: translateX(0%); } nav[data-state=\"open\"] ul li:nth-child(1) { -webkit-transition-delay: 0.16s; transition-delay: 0.16s; -webkit-transform: translateX(0px); transform: translateX(0px); opacity: 1; } nav[data-state=\"open\"] ul li:nth-child(2) { -webkit-transition-delay: 0.32s; transition-delay: 0.32s; -webkit-transform: translateX(0px); transform: translateX(0px); opacity: 1; } nav[data-state=\"open\"] ul li:nth-child(3) { -webkit-transition-delay: 0.48s; transition-delay: 0.48s; -webkit-transform: translateX(0px); transform: translateX(0px); opacity: 1; } nav[data-state=\"open\"] ul li:nth-child(4) { -webkit-transition-delay: 0.64s; transition-delay: 0.64s; -webkit-transform: translateX(0px); transform: translateX(0px); opacity: 1; } .btn { z-index: 1; overflow: hidden; background: transparent; position: relative; padding: 8px 50px; border-radius: 30px; cursor: pointer; font-size: 1em; letter-spacing: 2px; -webkit-transition: 0.2s ease; transition: 0.2s ease; font-weight: bold; margin: 5px 0px; } .btn.blue { border: 4px solid #6494ED; color: #6494ED; } .btn.blue:before { content: \"\"; position: absolute; left: 0; top: 0; width: 0%; height: 100%; background: #6494ED; z-index: -1; -webkit-transition: 0.2s ease; transition: 0.2s ease; } .btn.blue:hover { color: var(--white); background: #6494ED; -webkit-transition: 0.2s ease; transition: 0.2s ease; } .btn.blue:hover:before { width: 100%; } @media screen and (max-width: 768px) { body { display: block; } .container { margin-top: 70px; margin-bottom: 70px; } }"},{"title":"about","date":"2020-08-13T14:21:20.000Z","updated":"2020-11-30T13:20:04.480Z","comments":false,"path":"about/index.html","permalink":"https://www.geminilight.cn/about/index.html","excerpt":"","text":"光遇 向光而行，于此相遇 Gemini向光性 困在双子星座的失踪人口 正在修读软件工程学士+金融学二专 年少比较GEEK，现今喜欢CODE 盈时读书编程，闲时刷剧听歌 星辰浩瀚，你我皆一分布式节点，偶然相连 幸运在这里和你分享我的故事 个人爱好 时光白驹过隙，喜人难乐事易 学习方向 寻一生志趣前，不妨云游四海 我的博客 自知与博学相隔千里，未敢妄谈所写文字皆为真知灼见，只期望将自己所积知识之浅悟或总结、所乐事物之情感或经历分享于此。 查看博客更新计划"},{"title":"more","date":"2020-08-16T03:37:15.000Z","updated":"2020-08-17T13:04:46.101Z","comments":false,"path":"more/index.html","permalink":"https://www.geminilight.cn/more/index.html","excerpt":"","text":"更新计划 我的音乐 我的影视 我的书单 我的感悟 外链"},{"title":"categories","date":"2020-08-13T14:17:43.000Z","updated":"2020-08-13T17:18:04.113Z","comments":false,"path":"categories/index.html","permalink":"https://www.geminilight.cn/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-08-13T14:17:32.000Z","updated":"2020-08-15T15:39:21.374Z","comments":false,"path":"tags/index.html","permalink":"https://www.geminilight.cn/tags/index.html","excerpt":"","text":""},{"title":"books","date":"2020-08-16T03:11:59.000Z","updated":"2020-08-16T04:37:55.619Z","comments":false,"path":"more/books/index.html","permalink":"https://www.geminilight.cn/more/books/index.html","excerpt":"","text":""},{"title":"movies","date":"2020-08-16T03:42:07.000Z","updated":"2020-08-16T04:38:14.612Z","comments":false,"path":"more/movies/index.html","permalink":"https://www.geminilight.cn/more/movies/index.html","excerpt":"","text":""},{"title":"links","date":"2020-08-16T03:13:06.000Z","updated":"2020-08-16T04:38:05.913Z","comments":false,"path":"more/links/index.html","permalink":"https://www.geminilight.cn/more/links/index.html","excerpt":"","text":""},{"title":"music","date":"2020-08-16T03:41:45.000Z","updated":"2020-08-16T03:42:26.734Z","comments":false,"path":"more/music/index.html","permalink":"https://www.geminilight.cn/more/music/index.html","excerpt":"","text":""},{"title":"notes","date":"2020-08-16T03:39:46.000Z","updated":"2020-08-16T04:38:26.785Z","comments":false,"path":"more/notes/index.html","permalink":"https://www.geminilight.cn/more/notes/index.html","excerpt":"","text":""},{"title":"photos","date":"2020-08-14T06:56:45.000Z","updated":"2020-08-14T06:56:46.100Z","comments":true,"path":"more/photos/index.html","permalink":"https://www.geminilight.cn/more/photos/index.html","excerpt":"","text":""},{"title":"plan","date":"2020-08-16T03:37:15.000Z","updated":"2020-11-30T13:20:12.553Z","comments":false,"path":"more/plans/index.html","permalink":"https://www.geminilight.cn/more/plans/index.html","excerpt":"","text":"Article LeetCode 1 AD 【PPT设计】计算机学术会议中优秀PPT鉴赏 English How to Implement AI Blog hexo-NexT Construction Page plans books links music movies connection tutorial Beautifying categoriges horizon color Finashed"}],"posts":[{"title":"【论文笔记】GNN之GAT：Graph Attention Networks","slug":"ML - 机器学习/dl-gnn-gat","date":"2020-11-30T16:00:00.000Z","updated":"2020-12-01T14:43:24.315Z","comments":true,"path":"2020/12/01/ML - 机器学习/dl-gnn-gat/","link":"","permalink":"https://www.geminilight.cn/2020/12/01/ML%20-%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/dl-gnn-gat/","excerpt":"图神经网络（GNN）是当前深度学习领域研究的焦点，本文提出了一种GAT（graph attention networks）网络。它使用多头的masked self-attention层来为每个邻居节点分配不同的权重，优化了图卷积神经网络的平均加权的问题。 论文名称：Graph Attention Networks 论文作者：Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, Yoshua Bengio 发表期刊：ICLR-2018 (THU-A) 研究方向：GNN 图神经网络 关键技术：Masked self Attention, Multi Attention 主要创新：将多头注意力机制应用于图神经网络，来提升特征提取效果。 下载论文 | 源码链接","text":"图神经网络（GNN）是当前深度学习领域研究的焦点，本文提出了一种GAT（graph attention networks）网络。它使用多头的masked self-attention层来为每个邻居节点分配不同的权重，优化了图卷积神经网络的平均加权的问题。 论文名称：Graph Attention Networks 论文作者：Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, Yoshua Bengio 发表期刊：ICLR-2018 (THU-A) 研究方向：GNN 图神经网络 关键技术：Masked self Attention, Multi Attention 主要创新：将多头注意力机制应用于图神经网络，来提升特征提取效果。 下载论文 | 源码链接 论文简介 缩写释义 缩写 描述 全称 GNN 图神经网络 Graph Neural Network GCN 图卷积网络 Graph Convolutional Network GAT 图注意力网络 Graph Attention Network / 注意力机制 Attention mechanisms 研究背景 图结构数据是广泛存在的且较难处理 早期，为了将图数据结构适应神经网络模型，用网格化的图数据来进一步使用CNN进行特征提取。 之后，尝试扩展神经网络来直接对图数据进行处理 受到CNN卷积思想的启发，图卷积神经网络也被提出和不断完善，通常分为谱方法和非谱方法。 此外，注意力机制被广泛应用在端到端的任务模型中，它可以提取当前处理的输入与整个输入序列相关性更高的信息，从而提升了特征提取的效果。 本文提出一种基于注意力机制的图神经网络来GAT来使神经网络可以更高效的提取节点特征。其思想是通过关注邻域，遵循self-attention策略，计算图中每个节点的隐藏表示。 算法模型 Graph Attentional Layer Input/ Output 输入：图中\\(N\\)个节点\\(F\\)个特征的集合 \\[\\mathbf{h}=\\left\\{\\vec{h}_{1}, \\vec{h}_{2}, \\ldots, \\vec{h}_{N}\\right\\}, \\vec{h}_{i} \\in \\mathbb{R}^{F}\\] 输出：新的节点特征表示（\\(F&#39;\\)为潜在基数） \\[\\mathbf{h&#39;}=\\left\\{\\vec{h&#39;}_{1}, \\vec{h&#39;}_{2}, \\ldots, \\vec{h&#39;}_{N}\\right\\}, \\vec{h&#39;}_{i} \\in \\mathbb{R}^{F&#39;}\\] Self Attention 为了充分提取原始节点的特征信息，模型放弃了图的结构信息而运行每个节点都可以进行信息交换，同时利用 masked 自注意机制模型来注入结构信息，即对于节点\\(i\\)，仅计算其直接邻居\\(j \\in \\mathcal{N_i}\\)（包括节点\\(i\\)自身）之间的相关程度（权重系数）\\(e_{i,j}\\)，并利用归一化方法方便进行加权。 \\(e_{i,j}\\)表示节点\\(j\\)对节点\\(i\\)的重要程度，类似于打分分值，计算式如下 \\[e_{i j}=a\\left(\\mathbf{W} \\vec{h}_{i}, \\mathbf{W} \\vec{h}_{j}\\right)\\] 式中，\\(\\mathbf{W} \\in \\mathbb{R}^{F^{\\prime} \\times F}\\)是一个参数矩阵，\\(a: \\mathbb{R}^{F^{\\prime}} \\times \\mathbb{R}^{F^{\\prime}} \\rightarrow \\mathbb{R}\\)是一种自注意力机制。 然后，利用Softmax进行归一化： \\[\\alpha_{i j}=\\operatorname{softmax}_{j}\\left(e_{i j}\\right)=\\frac{\\exp \\left(e_{i j}\\right)}{\\sum_{k \\in \\mathcal{N}_{i}} \\exp \\left(e_{i k}\\right)}\\] 在本文中，注意力机制\\(a\\)是一个参数为\\(\\overrightarrow{\\mathbf{a}} \\in \\mathbb{R}^{2 F^{\\prime}}\\)的前馈神经网络，且利用LeakyReLU作激活函数，故权重系数也可写做： \\[\\alpha_{i j}=\\frac{\\exp \\left(\\text { Leaky } \\operatorname{ReLU}\\left(\\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{j}\\right]\\right)\\right)}{\\sum_{k \\in \\mathcal{N}_{i}} \\exp \\left(\\text { LeakyReLU }\\left(\\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{k}\\right]\\right)\\right)}\\] 式中，\\(·T\\)代表转置，\\(\\|\\)表示连接操作。 通过上述运算，我们得到了节点\\(i\\)与其邻居\\(j\\)的注意力权重\\(e_{i,j}\\)。之后进行加权求和，从而得到节点\\(i\\)的特征输出： \\[\\vec{h}_{i}^{\\prime}=\\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j} \\mathbf{W} \\vec{h}_{j}\\right)\\] 式中，\\(\\sigma\\)是激活函数。 Multi-head Attention 为了进一步提升注意力机制的性能，GAT利用了多头注意力机制，即\\(K\\)个注意力机制分别独立执行相应操作，然后将它们的输出连接起来生成最终输出： \\[\\vec{h}_{i}^{\\prime}=\\|_{k=1}^{K} \\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j}^{k} \\mathbf{W}^{k} \\vec{h}_{j}\\right)\\] 式中，\\(\\alpha_{ij}^{k}\\)表示第\\(k\\)个注意力机制\\(a_k\\)计算出的归一化注意力系数，\\(\\mathbf{W}^k是该注意力机制的参数矩阵\\)。注意到，在多头注意力机制下，最终输出中每个节点的特征数量为\\(KF&#39;\\) 特别地，如果在预测层（即Softmax上一层）执行多头注意力机制，将使用平均方法来代替连接操作： \\[\\vec{h}_{i}^{\\prime}=\\sigma\\left(\\frac{1}{K} \\sum_{k=1}^{K} \\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j}^{k} \\mathbf{W}^{k} \\vec{h}_{j}\\right)\\] 上图描述了连接操作和平均方法的基于多头注意力机制的GAT。 左图中，注意力机制\\(a(\\mathbf{W}\\vec{h_i},\\mathbf{W}\\vec{h_j})\\)分为两步： 线性加权得到注意力权值，即用神经网络参数\\(\\overrightarrow{\\mathbf{a}}^{T}\\)与\\(\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{j}\\right]\\)相乘 \\[e_{i,j} = \\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{j}\\right]\\] 非线性激活进行归一化，即用softmax对注意力权值进行归一化 \\[\\alpha_{i j}=\\operatorname{softmax}_{j}\\left(e_{i j}\\right)=\\frac{\\exp \\left(e_{i j}\\right)}{\\sum_{k \\in \\mathcal{N}_{i}} \\exp \\left(e_{i k}\\right)}\\] 加权求和得到最终输出，即用归一化注意力权值对各节点信息进行加权 \\[\\vec{h}_{i}^{\\prime}=\\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j} \\mathbf{W} \\vec{h}_{j}\\right)\\] 右图中，有三条不同颜色的线分别代表三个注意力机制在节点\\(i\\)处得到的结果，即此处\\(K=3\\)。之后，进行连接操作或平均操作得到最终输出\\(\\vec{h}&#39;\\)。 模型改进 计算高效。无需使用特征值分解等复杂的矩阵运算，且操作基本都可以实现并行。 可为同一个邻居的节点分配不同的重要性，提高模型表达能力。此外，注意权重可能有助于提高解释能力。 注意机制以共享的方式应用于图中的所有边，因此它不依赖于对全局图结构或需预先访问其所有节点的。我们无需访问整个图，而只需要访问所关注节点的邻节点即可。这一特点的作用主要有：a) 图不需要是无向的（如果边j→i不存在，我们可以省略计算αij）。 b) 它使我们的技术直接适用于归纳学习，包括在训练过程中完全看不见的图形上评估模型的任务。 它是建立在所有邻节点上的，而且无需假设任何节点顺序 GAT可以被看作是MoNet的一个特例。特殊地是，不同于MoNet实例相比，本文模型使用节点特征进行相似性计算，而不是节点的结构属性（假设预先知道图形结构）。具体来说，可以通过将伪坐标函数（pseudo-coordinate function）设为\\(u(x,y)=f(x) \\| f(y)\\)，其中\\(f(x)\\)表示节点\\(x\\)的特征，\\(\\|\\)；相应的权重函数则变成了\\(w_j(u)=softmax(MLP(u))\\)。 性能评估 数据集 测试任务 转导学习（Transductive Learning） 先观察特定的训练样本，然后对特定的测试样本做出预测（从特殊到特殊），这类模型如k近邻、SVM等。 使用了三个标准的引证网络数据集——Cora、Citeseer与Pubmed。在这些数据集中，节点对应于文档，边（无向的）对应于引用关系。节点特征对应于文档的BoW表示。每个节点拥有一个类别标签（在分类时使用softmax激活函数）。每个数据集的详细信息如下表所示： 归纳学习（Inductive Learning） 先从训练样本中学习到一定的模式，然后利用其对测试样本进行预测（即首先从特殊到一般，然后再从一般到特殊），这类模型如常见的贝叶斯模型。 本文使用了一个蛋白质关联数据集（protein-protein interaction, PPI），在其中，每张图对应于人类的不同组织。此时，使用20张图进行训练，2张图进行验证，2张图用于测试。每个节点可能的标签数为121个，而且，每个节点可以同时拥有多个标签（在分类时使用sigmoid激活函数） 评估指标 总结思考 利用多头注意力机制来为每个邻接节点赋予不同的注意力权重，提升特征提取效果 GAT模型无需了解整个图结构，只需知道每个节点的邻节点即可","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"DL","slug":"DL","permalink":"https://www.geminilight.cn/tags/DL/"},{"name":"GNN","slug":"GNN","permalink":"https://www.geminilight.cn/tags/GNN/"}],"author":"Gemini向光性"},{"title":"【论文汇总】Papers on VNE, SFCD and VNFP","slug":"RP - 科研论文/paper-nfv-papers-summary","date":"2020-11-30T16:00:00.000Z","updated":"2020-12-01T14:40:21.830Z","comments":true,"path":"2020/12/01/RP - 科研论文/paper-nfv-papers-summary/","link":"","permalink":"https://www.geminilight.cn/2020/12/01/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/paper-nfv-papers-summary/","excerpt":"Lastest update: Dec. 01, 2020. Contributed by Gemini Light(Tianfu Wang). Acronym Meaning VNE Virtual Network Embedding SFCD Service Function Chain Deployment VNFP Virtual Network Function Placement Content 1. Survey 2. Mathematical optimization-based 3. Heuristic-based 4. Nature Heuristic-based 5. Reinforcement learning-based 5.1 Basic RL 5.2 Value-based DRL 5.3 Policy-based DRL","text":"Lastest update: Dec. 01, 2020. Contributed by Gemini Light(Tianfu Wang). Acronym Meaning VNE Virtual Network Embedding SFCD Service Function Chain Deployment VNFP Virtual Network Function Placement Content 1. Survey 2. Mathematical optimization-based 3. Heuristic-based 4. Nature Heuristic-based 5. Reinforcement learning-based 5.1 Basic RL 5.2 Value-based DRL 5.3 Policy-based DRL Survey papers Recent Advances of Resource Allocation in Network Function Virtualization Publication: TPDS 2021 (CCF-A) Authors: Song Yang, Fan Li, Stojan Trajanovski, Ramin Yahyapour, Xiaoming Fu Keyworks: / Link: paper(To IEEE explore) A Survey on the Placement of Virtual Resources and Virtual Network Functions Publication: IEEE Communications Surveys &amp; Tutorials 2019 (Q1) Authors: Abdelquoddouss Laghrissi and Tarik Taleb Keyworks: / Link: paper Mathematical optimization-based Heuristic-based Toward Profit-Seeking Virtual Network Embedding Publication: INFOCOM 2014 (CCF-A) Authors: Long Gong, Yonggang Wen, Zuqing Zhu and Tony Lee Keyworks: VNE, GRC (Global Resource Control) Link: paper Nature Heuristic-based Reinforcement learning-based Basic RL MUVINE: Multi-Stage Virtual Network Embedding in Cloud Data Centers Using Reinforcement Learning-Based Predictions Publication: JSAC 2020 (CCF-A) Authors: Hiren Kumar Thakkar, Chinmaya Dehury, Prasan Kumar Sahoo Keyworks: VNE, Q-learning, ML(Machine Learning), Multi-Stage Objective: Maximizing the server resources utilization and minimizing the number of physical links used Link: paper Virtual Network Embedding via Monte Carlo Tree Search Publication: IEEE Trans on Cybernetics 2018 (CCF-B) Authors: Soroush Haeri and Ljiljana Trajkovi´c Keyworks: VNE, MCTS (Monte Carlo Tree Search) Link: paper Value-based DRL Optimal VNF Placement via Deep Reinforcement Learning in SDN/NFV-Enabled Networks Publication: JSAC 2019 (CCF-A) Authors: Jianing Pei, Peilin Hong, Miao Pan, Jiangqing Liu, Jingsong Zhou Keyworks: VNFP, DDQN (Double Deep Q Network), BIP (Binary Integer Programming) Link: paper DeepViNE: Virtual Network Embedding with Deep Reinforcement Learning Publication: INFOCOM 2019 (CCF-A) Authors: Mahdi Dolati, Seyedeh Bahereh Hassanpour, Majid Ghaderi, Ahmad Khonsari Keyworks: VNE, DQN (Deep Q Network), Multi-channels Representations Objective: Minimize the VN blocking probability Link: paper Policy-based DRL Automatic Virtual Network Embedding: A Deep Reinforcement Learning Approach With Graph Convolutional Networks Publication: JSAC 2020 (CCF-A) Authors: Zhongxia Yan, Jingguo Ge, Yulei Wu, Liangxiong Li, Tong Li Keyworks: VNE, A3C (Asynchronous Advantage Actor-Critic), GCN (Graph Convolutional Network) Objective: Minimizing the acceptance ratio and long-term average revenue Link: paper(To IEEE explore) Virtual Network Function Placement Optimization With Deep Reinforcement Learning Publication: JSAC 2019 (CCF-A) Authors: Ruben Solozabal, Josu Ceberio, Aitor Sanchoyerto, Luis Zabala, Bego Blanco, Fidel Liberal Keyworks: VNFP, PG (Policy Gradient), Seq2Seq (Sequence-to-Sequence) Objective: Minimizing the overall power consumption Link: paper(To IEEE explore) Multi-domain Non-cooperative VNF-FG Embedding: A Deep Reinforcement Learning Approach Publication: INFOCOM 2019 (CCF-A) Authors: Pham Tran Anh Quang, Abbas Bradai, Kamal Deep Singh, Yassine Hadjadj-Aoul Keyworks: VNF-FG, DDPG (Deep Deterministic Policy Gradient), Multi-domain Non-cooperative Objective: Maximize the number of allocated VNFs and VLs with the lowest cost Link: paper","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"Paper","slug":"Paper","permalink":"https://www.geminilight.cn/tags/Paper/"},{"name":"NFV","slug":"NFV","permalink":"https://www.geminilight.cn/tags/NFV/"},{"name":"DRL","slug":"DRL","permalink":"https://www.geminilight.cn/tags/DRL/"}],"author":"Gemini向光性"},{"title":"【论文笔记】Multi-domain non-cooperative VNF-FG embedding - A DRL approach","slug":"RP - 科研论文/paper-nfv-multi-domain-non-cooperative-vnf-fg-embedding","date":"2020-11-28T16:00:00.000Z","updated":"2020-12-01T08:13:07.344Z","comments":true,"path":"2020/11/29/RP - 科研论文/paper-nfv-multi-domain-non-cooperative-vnf-fg-embedding/","link":"","permalink":"https://www.geminilight.cn/2020/11/29/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/paper-nfv-multi-domain-non-cooperative-vnf-fg-embedding/","excerpt":"本文研究了多域非合作场景下的VNF放置问题，提出了一种深度强化学习DDPG算法与基于成本的首次拟合算法（CCF）相结合的方法来实现最大化VNF部署个数和最小化部署成本的目标。 论文简介 论文名称：Multi-domain Non-cooperative VNF-FG embedding: A deep reinforcement learning approach 论文作者：Quang Tran Anh Pham, Abbas Bradai, Kamal Deep Singh, Yassine Hadjadj-Aoul 发表期刊：INFOCOM-2019 (CCF-A) 研究方向：NFV 网络功能虚拟化 关键技术：多域非合作，虚拟网络功能嵌入, 深度强化学习 主要创新：多域非合作场景；多通道的VNF-FG请求矩阵表示；基于成本的首次拟合算法 下载论文","text":"本文研究了多域非合作场景下的VNF放置问题，提出了一种深度强化学习DDPG算法与基于成本的首次拟合算法（CCF）相结合的方法来实现最大化VNF部署个数和最小化部署成本的目标。 论文简介 论文名称：Multi-domain Non-cooperative VNF-FG embedding: A deep reinforcement learning approach 论文作者：Quang Tran Anh Pham, Abbas Bradai, Kamal Deep Singh, Yassine Hadjadj-Aoul 发表期刊：INFOCOM-2019 (CCF-A) 研究方向：NFV 网络功能虚拟化 关键技术：多域非合作，虚拟网络功能嵌入, 深度强化学习 主要创新：多域非合作场景；多通道的VNF-FG请求矩阵表示；基于成本的首次拟合算法 下载论文 问题定义 缩写释义 缩写 描述 全称 NFV 网络功能虚拟化 Network Function Virtualization VNF-FG 虚拟网络功能转发图 Virtual Network Function - Forwarding Graph VNF 虚拟网络功能 Virtual Network Function VL 虚拟链路 Virtual Link QoS 服务质量 Quality of Service DDPG deep deterministic policy gradient VNF-FG 每个VNF-FG由若干由VL连接起来的VNF组成 \\(\\mathcal{N&#39;}\\)表示VNF的集合，\\(|\\mathcal{N&#39;}|\\)为VNF个数 对于VNF，考虑\\(K_{VNF}\\)种资源，如CPU、RAM、Storage \\(h_{n&#39;,k}\\)表示VNF \\(n&#39;\\)对资源\\(k\\)的请求量 \\(h_{n&#39;} = [h_{n&#39;,0}, ..., h_{n&#39;,K_{VNF-1}}]\\)表示VNF \\(n&#39;\\)对各种资源的请求量 \\(\\mathcal{L&#39;}\\)表示VL的集合，\\(|\\mathcal{L&#39;}|\\)为VNF个数 对于VL，考虑\\(K_{VL}\\)种资源，如bandwidth、latency、packet loss \\(h_{l&#39;,k}\\)表示VNF \\(l&#39;\\)对资源\\(k\\)的请求量 \\(h_{l&#39;} = [h_{l&#39;,0}, ..., h_{l&#39;,K_{VNF-1}}]\\)表示VNF \\(l&#39;\\)对各种资源的请求量 问题约束 一个VNF可以被成功部署在一个有足够的资源的主机上，且只能部署在一个主机上 \\[\\sum_{n^{\\prime}} \\phi_{n}^{n^{\\prime}} h_{n^{\\prime}, k} \\leq r_{n, k}, \\forall n, k\\] \\[\\sum_{n} \\phi_{n}^{n^{\\prime}} \\leq 1, \\forall n^{\\prime}\\] 一个虚拟链路可以被部署在拥有足够资源且满足QoS要求的底层链路上 \\[\\sum_{l^{\\prime}} \\phi_{l}^{l^{\\prime}} h_{l^{\\prime}, b w} \\leq r_{l, b w}, \\forall l\\] \\[h_{l^{\\prime}, \\text {delay}} \\leq D\\left(\\phi^{\\prime^{\\prime}}\\right)\\] \\[h_{l^{\\prime}, \\text {loss}} \\leq R\\left(\\phi^{l^{\\prime}}\\right)\\] VNF-FG 请求 一个三维矩阵 \\(\\left|\\mathcal{N}^{\\prime}\\right| \\times\\left|\\mathcal{N}^{\\prime}\\right| \\times\\left(2 \\times K_{\\mathrm{VNF}}+K_{\\mathrm{VL}}\\right)\\)，可以看做\\(\\left(2 \\times K_{\\mathrm{VNF}}+K_{\\mathrm{VL}}\\right) \\text { -channel of }\\left|\\mathcal{N}^{\\prime}\\right| \\times\\left|\\mathcal{N}^{\\prime}\\right|\\)，即\\(\\left(2 \\times K_{\\mathrm{VNF}}+K_{\\mathrm{VL}}\\right)\\)个通道的\\(\\left|\\mathcal{N}^{\\prime}\\right| \\times\\left|\\mathcal{N}^{\\prime}\\right|\\)的矩阵表示。 \\(K_{VL}\\) 描述了虚拟链路的资源请求 \\(2 \\times K_{VNF}\\) 分别描述了源VNF和目的VNF的资源请求 资源价格 VNF \\(n&#39;\\)放置在底层节点\\(n\\)上时，其资源\\(m\\)的价格表示为\\(c^m_{n,n^{\\prime}}\\)，则VNF \\(n&#39;\\)的价格向量可表示为：\\(\\mathbf{c}_{n^{\\prime}}=\\left[\\mathbf{c}_{0, n^{\\prime}}, \\mathbf{c}_{1, n^{\\prime}}, \\ldots, \\mathbf{c}_{|\\mathcal{N}|-1, n^{\\prime}}\\right]\\)，其中\\(c_{i,n^{\\prime}}=[\\mathbf{c}_{0, n^{\\prime}}^{0},\\cdots,\\mathbf{c}_{0, n^{\\prime}}^{k_{VNF}-1}]\\)。因此，需要用\\(\\left|\\mathcal{N}^{\\prime}\\right| \\times\\left|\\mathcal{N}^{\\prime}\\right| \\times K_{VNF}\\)矩阵来表示。 VL \\(l&#39;\\)带宽资源的代价表示为\\(c_{i,l&#39;}\\)，则VL \\(l&#39;\\)的价格向量可表示为：\\(\\mathbf{c}_{l^{\\prime}}=\\left[\\mathbf{c}_{0, l^{\\prime}}, \\mathbf{c}_{1, l^{\\prime}}, \\ldots, \\mathbf{c}_{|\\mathcal{L}|-1, l^{\\prime}}\\right]\\)，需要用\\(\\left|\\mathcal{L}^{\\prime}\\right| \\times\\left|\\mathcal{L}^{\\prime}\\right|\\)来表示。 这些价格由每个与决定，它们会被发送到中心客户。 算法模型 多域非合作架构 在该文中，环境是由多个非合作的域和一个中心客户（client）组成的。这些域有这些特征： 每个域都没有其他域的拓扑结构和资源信息 每个域不与其他域进行通信， 每个域单独做出决策将发送至中心客户，由中心客户根据价格进行选择 大致的决策流程如下： 中心代理将VNF-FG请求处理为一个三维向量，即state，然后发送给每个域 每个域使用actor网络根据state计算出action。每个域的动作\\(A_i\\)是向中心客户提出的价格，如\\(c_{n, n^{\\prime}}^{k}, \\forall n \\in \\mathcal{N}_{i}\\)和\\(c_{l, l^{\\prime}}, \\forall l \\in \\mathcal{L}_{i}\\)分别代表节点和链路成本。 中心代理根据这些信息作出最终决策，每个域根据决策来部署VNF和VL，最后得到相应奖励 深度强化学习 DDPG 马尔科夫决策 MDP 环境 Environment：多个域和一个中心客户 状态 State：经过处理的VNF-FG请求，是一个三维矩阵。 动作 Action：行为就像是对出售其资源的域名的竞价，它包括对节点资源和链路资源的报价。 奖励 Reward：根据部署质量和资源报价，中心代理返回给每个域相应奖励 \\[r_{i}=\\sum_{n^{\\prime} \\in \\mathcal{N}^{\\prime}} \\sum_{n \\in \\mathcal{N}_{i}} \\sum_{k \\in K_{c}} \\omega_{n}^{n^{\\prime}} c_{n, n^{\\prime}}^{k} h_{n^{\\prime}, k}+\\sum_{l \\in \\mathcal{L}_{i}} \\sum_{l^{\\prime} \\in \\mathcal{L}^{\\prime}} \\omega_{l}^{l^{\\prime}} c_{l, l^{\\prime}} h_{l^{\\prime}, b w}\\] 式中，\\(w_n^{n&#39;}\\)和\\(w_n^{n&#39;}\\)表示放置成功二进制位，当且仅当节点和链路被成功放置且满足服务质量时才为1。 代理架构 Agent DDPG由两个神经网络组成 Actor network: 学习策略。根据当前策略和输入的\\(s_t\\)来生成动作，要注意的是，动作被添加了噪声\\(N\\)来使agent更好地探索环境。 Critic network: 学习Q值。评估一个动作的优劣，来使actor学习到更好地策略。 actor和critic神经网络由多种层组成来提取state中的信息，特别地，critic额外使用了卷积层来提取动作的特征： 3层卷积层 convolutional layers 卷积层\\(i\\)的过滤器和卷积核的大小为\\(C_i\\)和\\((F_i, F_i)\\) 卷积层的输出反映了虚拟链路及其属性间的相互影响 平均池化层 average pool layers 减少参数数量和防止过拟合 全连接层 Fully Connected layers 将这些反映state信息相互影响的中间输出映射为动作 收到每个域返回的动作（资源竞价），中心客户会做出最终的决定并执行，然后每个域会依据提供的资源收到相应的奖励，最后DRL代理会计算loss来更新参数。 对于域\\(i\\)，其目标是找到一个从VNF-FG请求到本地动作的映射策略：\\(\\mu_i:S \\rightarrow A_i\\)来最大化获得奖励。 决策算法 CFF 在收集了来自不同域\\(A_i\\)的价格后，中心客户必须做出决定来部署其VNF-FG。虽然很难保证一条路径能够满足虚拟链路所需的QoS，但是可以保证VNFs的资源需求。因此，在部署VNF时，决策必须考虑底层节点的容量以及部署的成本。 该文使用了将一种资源分配算法First-Fit算法改进为基于成本的First-Fit（CFF）算法来进行从VNF到底层节点的决策生成： 输入：每个域的动作\\(A_i\\) 输出：VNF的映射集合\\(\\phi_n^{n&#39;}\\) 初始化 \\(\\phi_n^{n&#39;}=0, \\forall n, n&#39;\\), \\(A_* \\leftarrow [A_1, \\cdots, A_D]\\) 将全局动作A_*分割为与VNF相关的成本\\(A_{*,vnf}\\)和与VL相关的成本\\(A_{*,vl}\\) 对于每个VNF \\(i\\)： 实际部署成本等于VNF \\(i\\)的成本与其资源请求量\\(h_i\\)的点乘：\\(P = A_{*,vnf}[i]=c_i \\cdot h_i\\)，由此可得到每个底层节点部署当前VNF的成本 按照部署成本\\(P\\)进行升序排列 对于排列后的域序列中的单个域\\(j\\)： 中心代理具有\\(j\\)的域\\(D(j)\\)发送请求 如果域$D(j)接受了该请求，那么 \\(\\phi_n^{n&#39;}=1\\)，域\\(D(j)\\)部署j到节点i上 映射VNF策略的目标是最大化部署个数和最小化部署成本。映射虚拟链路\\(l&#39;\\)时，根据\\(A_{*,vl}[l&#39;]\\)作为链路权重，使用Dijkstra算法来寻找最小成本的链路。 性能评估 设计实验 网络拓扑设置 BtEurope网络拓扑：24个节点和37个全双工边 链路资源容量：20 Mbps, 30 Mbps, 50 Mbps, 100 Mbps随机分配 节点资源容量：\\((0.3, 2.0)\\) 随机分配 使用延迟和丢包率来评价网络虚拟链路的部署质量 VNF-FG配置 3到6个VNF组成，VNF连接率为0.5 VNF资源请求量被进行归一化 VL请求：\\((1,30)\\) Mbps随机分配，延迟为1100毫秒，延迟率为0%0.5% 神经网络参数 符号 含义 取值 \\ 优化器 Adam \\ actor学习率 \\(10^{-4}\\) \\ critic学习率 \\(10^{-3}\\) \\(\\gamma\\) 折扣因子 0.99 \\(\\tau\\) target网络更新系数 =0.001 \\ batch size 32 \\ 全连接层unit个数 300 \\ 卷积层卷积核 \\((4,4),(2,2),(5,5)\\) 对比算法 CFF-SD single domain with CFF，单域CCF算法，是非竞争的 CFF-3D three domain with CFF，三域使用CCF算法 SA simulated annealing algorithm，模拟退火算法 SA-CFF simulated annealing algorithm with CFF，模拟退火和CCF算法结合 评估指标 总结思考 该文研究了非合作多域场景下的VNF放置问题 对于VNF和VL均考虑多种资源约束 将VNF-FG请求处理为一个包含VNF和VL请求信息的3维矩阵 使用了DDPG的深度强化学习方法来训练神经网络 改进了First Fit算法来达到最小化部署成本的目标","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"Paper","slug":"Paper","permalink":"https://www.geminilight.cn/tags/Paper/"},{"name":"NFV","slug":"NFV","permalink":"https://www.geminilight.cn/tags/NFV/"},{"name":"DRL","slug":"DRL","permalink":"https://www.geminilight.cn/tags/DRL/"}],"author":"Gemini向光性"},{"title":"【科研思维】科研方法与精神","slug":"RP - 科研论文/research-great-researcher","date":"2020-11-05T16:00:00.000Z","updated":"2020-11-30T07:43:09.308Z","comments":true,"path":"2020/11/06/RP - 科研论文/research-great-researcher/","link":"","permalink":"https://www.geminilight.cn/2020/11/06/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/research-great-researcher/","excerpt":"关于一些学者对科研历程、科研方法和科研精神的总结。（上次更新：2020/11/06） 整理自： 智源研究院 学者： RUC 赵鑫 副教授 THU 唐杰 教授 THU 刘知远 副教授 UCAS 沈华伟 研究员","text":"关于一些学者对科研历程、科研方法和科研精神的总结。（上次更新：2020/11/06） 整理自： 智源研究院 学者： RUC 赵鑫 副教授 THU 唐杰 教授 THU 刘知远 副教授 UCAS 沈华伟 研究员 学生 本科生的问题 —— RUC 赵鑫 副教授 选择太多，太多时间花在选择上，而没有沉下心来做科研；倘若静下心来一直做，肯定会做出很好的成果。 博士生的三种境界 —— THU 刘知远 副教授 境界一：能够解决开放问题——面对一片未知，找出一条路。（文献调研） 境界二：具备科研方向感——知道哪些问题是重要且能被解决的。（找到问题） 境界三：负有领域责任感——对领域未来发展，负有责任感；领域兴亡，匹夫有责。（领域责任） 赠予同学的三句话 —— RUC 赵鑫 副教授 送给各位来我网页驻足同学三句话 童第周先生的两句话： （1）“一定要争气。我并不比别人笨。别人能办到的事，我经过努力，一定也能办到。” （2）“一定要争气。中国人并不比外国人笨。外国人认为很难办的事，我们中国人经过努力，一定能办到。” 还有一句《追梦赤子心》的歌词： - （3）“为了心中的美好，不妥协，一直到老” 学生 -&gt; 学者 从学生到学者的四个阶段 —— THU 唐杰教授 阶段一：在引路人的带领下，踏踏实实把一件事做到极致；（Top Conference or Top Journal） 阶段二：想一个Idea，在被告知哪些不能做后，把能做的部分做到极致；（Top Conference or Top Journal） 阶段三：完全独立地想一个Idea，并独立地做完、做好； （Independent） 阶段四：能够带着第一阶段的人，引导他把一件事情做好。（Expand） 学者 优秀学者的三层境界 —— CAS 沈华伟 研究员 1、解决问题，为领域发展做贡献；（科研） 2、传道受业，带起一批人；（团队） 3、突破自我，服务社会。（贡献） 学而优则仕(X)，学而优则向其他领域拓展做贡献 正确的科研道路 —— RUC 赵鑫 副教授 AI -&gt; 研究点 打基础：入门资源 看论文：快速浏览 -&gt; 感兴趣方向 -&gt; 顶会发展 -&gt; 哪些想做 -&gt; 研究点 研究点：综述文章 -&gt; 研究进展与脉络 学术生涯的核心精神 —— THU 唐杰教授 专注，专注，再专注 不要在乎别人的眼光，只管专注做 做事情追求极致","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"Research","slug":"Research","permalink":"https://www.geminilight.cn/tags/Research/"}],"author":"Gemini向光性"},{"title":"【Web】《CQU软件综合实践平台》项目总结","slug":"WD - WEB开发/wd-web-cquse-system","date":"2020-09-03T08:56:00.000Z","updated":"2020-11-30T07:30:13.138Z","comments":true,"path":"2020/09/03/WD - WEB开发/wd-web-cquse-system/","link":"","permalink":"https://www.geminilight.cn/2020/09/03/WD%20-%20WEB%E5%BC%80%E5%8F%91/wd-web-cquse-system/","excerpt":"在大二小学期软件实训课程中，自己做了一个“CQU软件综实践平台”的项目，于是在此总结一些自己第一次做自己的全栈开发项目的经验。（其实这篇总结应该很早就写的，至于为什么拖到了现在？“不愧是我——那只Monkey又在作怪”）","text":"在大二小学期软件实训课程中，自己做了一个“CQU软件综实践平台”的项目，于是在此总结一些自己第一次做自己的全栈开发项目的经验。（其实这篇总结应该很早就写的，至于为什么拖到了现在？“不愧是我——那只Monkey又在作怪”） 前言 为什么 为什么会选择做“CQU软件综合实践平台”这个项目呢？主要是因为自己在入门Vue后便很少去实践，关于后端的知识也少有动力去精进，恰巧课程名称《软件综合实践》且主要假以钉钉、QQ作为课程平台。于是在此特定的时机场景，便萌生了做一个重庆大学软件综合实践平台的想法。 做什么 现有的网络课程平台或是专门针对实验课程的平台繁多且不乏高质量网站，个人深知能力有限，并不渴求可以做出功能十分完善、需求十分满足的工业级项目。更多的出于自我学习的目的，项目偏向于一些必要需求的实现和一些特定场景的优化，因此，在前期需求分析阶段所作出的分析也主要是针对所学课程当中的常见需求和场景。 怎么做 该平台是基于B/S的实验课程管理系统，故离不开前端与后端的技术支撑。在具体实现过程中，主要用到了以下技术栈： 前端：HTML、CSS、JS、Vue、Element UI 后端：SpringBoot、Redis、Mybatis plus、AliYun oss 数据库：MySQL、CURD、乐观锁、触发器、范式设计 展示 以下为项目中部分界面的展示 统一登录入口 学生功能页面 学生主页 学生签到界面 学生上传报告 学生成绩查询 学生个人中心 教师功能页面 教师主页 教师登记成绩 教师查看选题 后台功能页面 学生信息管理 修改学生信息 总结 前端方面 Vue、React、Angular等等这些流行的前端框架一定程度上改变了前端开发的模式，工程化地提高了前端开发的效率，但也对前端开发提出了更高的要求。 项目中，通过进一步对Vue的学习，发现Vue很多新的特性和难的特性都可以在JavaScript、TypeScript中找到源痕迹。Vue在新beta版本中加入的新特性，也越来越偏重于TS的语言特性，更加注重模板与类的使用。但奈何个人对TypeScript了解甚少，因此对于一些语法糖的使用规范理解得并不是很好。所以编码时，秉承着真不会就不用的原则..还有要感谢Element UI让我写出了还能看的UI。 感想：基础为底石，方能站得稳，看得深，做得好。 后端方面 从Django到Springboot的过渡可能如学语言时从python到java的过渡，虽然可说是由“简”入“繁”，但整个项目体验下来，不得不承认java语言的工程性会更强些。 整个项目的完成离不开对各种插件的使用，如Mybatis-plus、lombok、easy-excel等等，这些插件对一些常见的方法进行了封装实现，明显提高了开发效率。但其实过渡封装反而会对自定义方法的实现带来不便。 另外，Mybatis-plus官方文档在自定义SQL方面，特别xml实现方面，写的就很…不容易理解，也可能需要Mybatis的基础吧，然而课程时间限制来不及去补充了解下。现在感觉要想真正了解一些高效的插件，离不开对其实现代码的阅读。 感想：所谓的高效开发往往可能是对底层实现的不求甚解。 数据库方面 原本以为数据库应该是整个项目最简单的部分，但不得承认数据库改动次数还是挺多的，而且数据库的一变前后端都得变，就很繁琐。虽说数据库设计上也算还可以，但是由于数据量、实践和个人能力的问题，对数据库中关于并发、缓存、锁粒度等等并没有得到很好地应用。 此外，《高性能MySQL》这本书让我知道数据库理论并不是简单的，要想达到最优的性能，就必须了解如join、in等等这些选择方式背后的原理实现。当然，自以为然地掌握了原理并不是软件工程的最终目的，考卷上三四张表的设计已经满足了考察水平和时间要求，但现实生活中应用场景要远远复杂，真正要达到较高的掌握程度就要真正去实践。 感想：检验理论掌握程度的最佳标准是实践。 后记 三周的小学期对于拖延症患者而言并不长，精确些来说只是三天。至于说Deadline前的三天是如何度过，我只能期望大脑中的Monkey尽早能更加有远见些。","categories":[{"name":"WD - 网站开发","slug":"WD-网站开发","permalink":"https://www.geminilight.cn/categories/WD-%E7%BD%91%E7%AB%99%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"front-end","slug":"front-end","permalink":"https://www.geminilight.cn/tags/front-end/"},{"name":"Web","slug":"Web","permalink":"https://www.geminilight.cn/tags/Web/"}],"author":"Gemini向光性"},{"title":"【随笔】时光刻痕——记博客重启","slug":"MY - 感悟随笔/my-record-our-moments","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-26T14:30:00.344Z","comments":true,"path":"2020/08/25/MY - 感悟随笔/my-record-our-moments/","link":"","permalink":"https://www.geminilight.cn/2020/08/25/MY%20-%20%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/my-record-our-moments/","excerpt":"日历翻至八月，空气日渐升温。在这个特殊的年份，暑假的宿舍只余下我一人——这也是我第一次独自在远离家乡的“专属”空间中“自由”生活。","text":"日历翻至八月，空气日渐升温。在这个特殊的年份，暑假的宿舍只余下我一人——这也是我第一次独自在远离家乡的“专属”空间中“自由”生活。 始 新颖的事物总能在最初的时刻吸引好奇的目光，但即便它再精致华丽，也大都会因日久生乏味而迎来退散的人潮。 最后一位舍友拉着行李走出了宿舍，作为初试者的自己也全然不知接下来的40天会有怎样的故事来填充生活，只是想到可以体验“真正”的成年人独居生活就满心欢喜。机械键盘随意地敲出节奏，音响外放着喜欢的音乐，灯光只按自己的时间表作息。狭小的寝室空间里挤满了自由的字样，我身处其中，随性而活。 生活逐渐循环往复，曾以为的趣事给予的多巴胺似乎也在线性消淡。思维总爱东奔西跑，它也开始忧心自己未来是否一直这样单调。惊慌把储蓄数天的存乐罐打翻，忧虑把原本红色的神经染成蓝色，难道始终有趣事物只是海市蜃楼般存在吗？ 思 时光从不为单个人驻足，每个人都乘着路过拼命地向其中塞满经历。少数轰轰烈烈为世人所铭记，大多平平淡淡连自己都忘却。 滴答清单上计划着每日的生活，但偶然翻阅历史，发现还是那些熟悉的条目：“代码”、“论文”、“电影”、“跑步”......前天写代码、看电影；昨天读论文、跑跑步.....难道生活真的就只是这些事情的排列组合吗？我试图回忆自己刚过的数天，发现原本清晰完整的记忆已被雨水冲刷殆尽。难道平凡的生活中真的就没有值得自己珍藏的画面吗？我开始有点心悸：需要多少爱好才能让生活多彩，需要多努力记忆才能不淡忘？ 悟 概念之下藏有形象之地 或许这世间本就不存在昼夜耀眼的事物，但这也不意味着平凡人生的平淡生活必定庸碌无奇。或许值得铭记于心的记忆一直都在发生，只是因那些概括性的标签而被自己忽略。 我试图缘着回忆里所剩无几的痕迹，探寻那时或许值得珍藏的碎片。同样是写代码，某一天我重构了我的暑期实训项目，那是我第一个全栈开发的项目；而另一天我写出了完整的A3C算法，那是我学强化学习以来所构建第一个完整的模型......同样是看电影，有一天《天气之子》播放在屏幕上，依旧是我很欣赏的新海诚画风；有一天我重温了《越光宝盒》，被无厘头的情节逗得哈哈大笑......掀开“代码”、“电影”这些抽象概念的面纱，原来那些我一直寻找着的记忆光点一直栖息于此。美好事物并非永恒，亦未绝迹，它们始终都在每个人的生活里闪耀着。无需把目光扩宽或是聚焦，只轻轻抚去那层笼统概念的遮蔽，便发现我们平凡的生活亦熠熠生辉。 行 时间流淌不息，记忆刻痕于石 我们穷极一生追求快乐与意义。有人生而不凡，一举一动皆会载入史书；有人生而平凡，奋斗不渝依旧默默无闻。所幸我们都拥有自己的记忆，不必乞求他人的旁观，亦可留痕于时间。所幸我们都拥有自己的故事，不必渴望他人的相伴，亦可闪烁于回忆。 沙滩上的足迹总有一天会被冲散，我们无力阻拦时间海浪，但可以将记忆的痕迹加深。将路途中每份值得铭记的感动和泪水镌刻于石，置于沙滩。哪怕只自己一人在乎与阅读，它们都始终躺在海滩上，愈冲刷愈闪亮。或许偶尔有人途径此处，不经意地捡起其中一块无奇的石头，却好奇地细瞥其上的文字，记录的故事或恰可给予他一些帮助。 每个人都有独家记忆值得被刻录于石。时光流逝不止，或骇浪冲击，或风吹日晒，它们却日益生辉。 愿 此后某天，携着日历上模糊的记忆，我浏览起自己的博客。捡起一块对应日期的石块，迎着海风阅读石上字痕，原来一些回忆不曾随时间降温，重温依旧炽热。","categories":[{"name":"MY - 感悟随笔","slug":"MY-感悟随笔","permalink":"https://www.geminilight.cn/categories/MY-%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://www.geminilight.cn/tags/Blog/"},{"name":"随笔","slug":"随笔","permalink":"https://www.geminilight.cn/tags/%E9%9A%8F%E7%AC%94/"}],"author":"Gemini向光性"},{"title":"【论文笔记】VNF placement optimization with DLR","slug":"RP - 科研论文/paper-nfv-vnf-placement-optimization-drl","date":"2020-08-20T15:42:32.000Z","updated":"2020-11-30T13:08:11.999Z","comments":true,"path":"2020/08/20/RP - 科研论文/paper-nfv-vnf-placement-optimization-drl/","link":"","permalink":"https://www.geminilight.cn/2020/08/20/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/paper-nfv-vnf-placement-optimization-drl/","excerpt":"本篇论文对资源消耗成本最小化的强化学习Policy Gradient算法，结合Seq2Seq模型，提出了一种虚拟网络服务放置的优化算法。 论文简介 论文名称：Virtual Network Function placement optimization with Deep Reinforcement Learning 论文作者：Ruben Solozabal, Josu Ceberio, Aitor Sanchoyerto, Luis Zabala, Bego Blanco, Fidel Liberal 发表期刊：JSAC-2020 (CCF-A) 研究方向：NFV 网络功能虚拟化 关键技术：NFV 网络功能虚拟化, RL 强化学习, Seq2Seq 主要创新：以最小化资源消耗为目标，并用策略梯度算法结合Seq2Seq来搭建模型 论文地址","text":"本篇论文对资源消耗成本最小化的强化学习Policy Gradient算法，结合Seq2Seq模型，提出了一种虚拟网络服务放置的优化算法。 论文简介 论文名称：Virtual Network Function placement optimization with Deep Reinforcement Learning 论文作者：Ruben Solozabal, Josu Ceberio, Aitor Sanchoyerto, Luis Zabala, Bego Blanco, Fidel Liberal 发表期刊：JSAC-2020 (CCF-A) 研究方向：NFV 网络功能虚拟化 关键技术：NFV 网络功能虚拟化, RL 强化学习, Seq2Seq 主要创新：以最小化资源消耗为目标，并用策略梯度算法结合Seq2Seq来搭建模型 论文地址 问题定义 专业词汇 缩写 描述 全名 NFV 网络功能虚拟化 Network Function Virtualization VNF 虚拟网络请求 Virtual Network Functions NS 网络服务 Network Service VNF-FGE VNF正向图嵌入问题 VNF Forward Graph Embedding problem VNF-FGE 对于一组网络服务， 它必须被最优地被放置在一组主机服务器上，即 \\(h \\in H\\) 满足主机服务器在计算、存储链路容量等方面的现在，即 \\(s \\in S\\) 问题目的：最小化对底层资源的消耗 \\(H = \\{ h_1, h_2, \\dots, h_n \\}\\) 主机服务器 \\(V\\) 可用的VNF \\(m \\in \\{1, \\dots, M\\}\\) 一系列VNF组成的网络服务 \\(s \\in \\{f_1, f_2, \\dots, f_m \\}\\) ，且\\(f \\in M\\) 一条服务链 \\(S\\) 所有的服务链组合 \\(x \\in \\{0, 1\\}^{m\\times n}\\) \\(x_{fh}\\) 表示功能 \\(f \\in V\\) 是否被放置在主机 \\(h \\in H\\) 中（1放置，0未放置） 动作搜索路径：\\(\\Omega = \\{0,1\\}^{m \\times n}\\) s.t. \\(\\left.\\sum_{h} x_{f h}=1 \\forall f \\in s\\right\\}\\) 对于一条服务链，它只能放置在一个主机一次 辅助变量 \\(y_h \\in \\{0,1\\}\\)：服务器激活变量。1代表服务器正在执行VNF，0反之 \\(g_i \\in \\{0,1\\}\\)：链路激活变量。1代表链路正在承载流量，0反之 功耗相关 服务器主机功耗 \\(W_h^{cpu}\\) 激活运行时（\\(y_h = 1\\)）的最低功耗为 \\(W_h^{min}\\) 功耗随着VNF的CPU需求总和而增加（线性增长） 链路消耗 \\(W_{net}\\) 带宽利用量 x 单位成本 可用资源 \\(r \\in R\\) 算法模型 性能评估 设计实验 对比算法 评估指标 主要创新 基于RL+GCN的自动虚拟网络嵌入算法 并行的策略梯度训练方法 多指标的奖励函数 总结思考 GCN较CNN可以更好地提取非欧数据的特征 A3C算法较其他RL算法性能表现更佳 并行的梯度训练策略更适应于实际场景 多指标的Reward可以让Agent学习到更好地策略来提高收益 在模型评估部分，实验的设计比较完善","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"DL","slug":"DL","permalink":"https://www.geminilight.cn/tags/DL/"},{"name":"Paper","slug":"Paper","permalink":"https://www.geminilight.cn/tags/Paper/"},{"name":"NFV","slug":"NFV","permalink":"https://www.geminilight.cn/tags/NFV/"},{"name":"DRL","slug":"DRL","permalink":"https://www.geminilight.cn/tags/DRL/"}],"author":"Gemini向光性"},{"title":"【SciPy】Sparse稀疏矩阵主要存储格式总结","slug":"DA - 数据分析/da-scipy-sparse","date":"2020-08-17T16:00:00.000Z","updated":"2020-11-30T07:36:35.831Z","comments":true,"path":"2020/08/18/DA - 数据分析/da-scipy-sparse/","link":"","permalink":"https://www.geminilight.cn/2020/08/18/DA%20-%20%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/da-scipy-sparse/","excerpt":"在数据科学和深度学习等领域常会采用矩阵格式来存储数据，但当矩阵较为庞大且非零元素较少时，运算效率和存储有效率并不高。所以，通常我们采用Sparse稀疏矩阵的方式来存储矩阵，提高存储和运算效率。下面将对SciPy中七种常见的存储方式（COO/ CSR/ CSC/ BSR/ DOK/ LIL/ DIA）的概念和用法进行介绍和对比总结。","text":"在数据科学和深度学习等领域常会采用矩阵格式来存储数据，但当矩阵较为庞大且非零元素较少时，运算效率和存储有效率并不高。所以，通常我们采用Sparse稀疏矩阵的方式来存储矩阵，提高存储和运算效率。下面将对SciPy中七种常见的存储方式（COO/ CSR/ CSC/ BSR/ DOK/ LIL/ DIA）的概念和用法进行介绍和对比总结。 稀疏矩阵简介 稀疏矩阵 numpy.sparse 稀疏矩阵 sparse matrix numpy.ndarray 密集矩阵 array matrix numpy.matrix 密集矩阵 dense matrix 稀疏矩阵 具有少量非零项的矩阵 - Number of Non-Zero (NNZ) &lt; 0.5 （在矩阵中，若数值0的元素数目远多于非0元素的数目，并且非0元素分布没有规律） 矩阵的稠密度 非零元素的总数比上矩阵所有元素的总数为矩阵的稠密度。 By Matt 压缩存储 存储矩阵的一般方法是采用二维数组，其优点是可以随机地访问每一个元素，因而能够容易实现矩阵的各种运算。 对于稀疏矩阵，它通常具有很大的维度，有时甚大到整个矩阵（零元素）占用了绝大部分内存 采用二维数组的存储方法既浪费大量的存储单元来存放零元素，又要在运算中浪费大量的时间来进行零元素的无效运算。因此必须考虑对稀疏矩阵进行压缩存储（只存储非零元素）。 12345678910111213141516from scipy import sparsehelp(sparse)&#x27;&#x27;&#x27;Sparse Matrix Storage FormatsThere are seven available sparse matrix types: 1. csc_matrix: Compressed Sparse Column format 2. csr_matrix: Compressed Sparse Row format 3. bsr_matrix: Block Sparse Row format 4. lil_matrix: List of Lists format 5. dok_matrix: Dictionary of Keys format 6. coo_matrix: COOrdinate format (aka IJV, triplet format) 7. dia_matrix: DIAgonal format 8. spmatrix: Sparse matrix base clas&#x27;&#x27;&#x27; 矩阵属性 123456789101112131415161718from scipy.sparse import csr_matrix### 共有属性mat.shape # 矩阵形状mat.dtype # 数据类型mat.ndim # 矩阵维度mat.nnz # 非零个数mat.data # 非零值, 一维数组### COO 特有的coo.row # 矩阵行索引coo.col # 矩阵列索引### CSR\\CSC\\BSR 特有的bsr.indices # 索引数组bsr.indptr # 指针数组bsr.has_sorted_indices # 索引是否排序bsr.blocksize # BSR矩阵块大小 通用方法 12345678910111213141516171819202122232425262728293031import scipy.sparse as sp### 转换矩阵格式tobsr()、tocsr()、to_csc()、to_dia()、to_dok()、to_lil()mat.toarray() # 转为arraymat.todense() # 转为dense# 返回给定格式的稀疏矩阵mat.asformat(format)# 返回给定元素格式的稀疏矩阵mat.astype(t) ### 检查矩阵格式issparse、isspmatrix_lil、isspmatrix_csc、isspmatrix_csrsp.issparse(mat)### 获取矩阵数据mat.getcol(j) # 返回矩阵列j的一个拷贝，作为一个(mx 1) 稀疏矩阵 (列向量)mat.getrow(i) # 返回矩阵行i的一个拷贝，作为一个(1 x n) 稀疏矩阵 (行向量)mat.nonzero() # 非0元索引mat.diagonal() # 返回矩阵主对角元素mat.max([axis]) # 给定轴的矩阵最大元素### 矩阵运算mat += mat # 加mat = mat * 5 # 乘mat.dot(other) # 坐标点积resize(self, *shape)transpose(self[, axes, copy]) 稀疏矩阵分类 COO - coo_matrix Coordinate Matrix 对角存储矩阵 采用三元组(row, col, data)(或称为ijv format)的形式来存储矩阵中非零元素的信息 三个数组 row 、col 和 data 分别保存非零元素的行下标、列下标与值（一般长度相同） 故 coo[row[k]][col[k]] = data[k] ，即矩阵的第 row[k] 行、第 col[k] 列的值为 data[k] 当 row[0] = 1 , column[0] = 1 时， data[0] = 2 ，故 coo[1][1] = 2 当 row[3] = 0 , column[3] = 2 时， data[3] = 9 ，故 coo[0][3] = 9 适用场景 主要用来创建矩阵，因为coo_matrix无法对矩阵的元素进行增删改等操作 一旦创建之后，除了将之转换成其它格式的矩阵，几乎无法对其做任何操作和矩阵运算 优缺点 ①优点 转换成其它存储格式很快捷简便（tobsr()、tocsr()、to_csc()、to_dia()、to_dok()、to_lil()） 能与CSR / CSC格式的快速转换 允许重复的索引（例如在1行1列处存了值2.0，又在1行1列处存了值3.0，则转换成其它矩阵时就是2.0+3.0=5.0） ②缺点 不支持切片和算术运算操作 如果稀疏矩阵仅包含非0元素的对角线，则对角存储格式(DIA)可以减少非0元素定位的信息量 这种存储格式对有限元素或者有限差分离散化的矩阵尤其有效 实例化方法 coo_matrix(D)：D代表密集矩阵； coo_matrix(S)：S代表其他类型稀疏矩阵 coo_matrix((M, N), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d， coo_matrix((data, (i, j)), [shape=(M, N)]))：三元组初始化 i[:] : 行索引 j[:] : 列索引 A[i[k], j[k]]=data[k] 特殊属性 data：稀疏矩阵存储的值，是一个一维数组 row：与data同等长度的一维数组，表征data中每个元素的行号 col：与data同等长度的一维数组，表征data中每个元素的列号 代码示例 1234567891011121314151617181920212223242526272829303132# 数据row = [0, 1, 2, 2]col = [0, 1, 2, 3]data = [1, 2, 3, 4]# 生成coo格式的矩阵# &lt;class &#x27;scipy.sparse.coo.coo_matrix&#x27;&gt;coo_mat = sparse.coo_matrix((data, (row, col)), shape=(4, 4), dtype=np.int)# coordinate-value formatprint(coo)&#x27;&#x27;&#x27;(0, 0) 1(1, 1) 2(2, 2) 3(3, 3) 4&#x27;&#x27;&#x27;# 查看数据coo.datacoo.rowcoo.col# 转化array# &lt;class &#x27;numpy.ndarray&#x27;&gt;coo_mat.toarray()&#x27;&#x27;&#x27;array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 4], [0, 0, 0, 0]])&#x27;&#x27;&#x27; CSR - csr_matrix Compressed Sparse Row Matrix 压缩稀疏行格式 csr_matrix是按行对矩阵进行压缩的 通过 indices, indptr，data 来确定矩阵。 data 表示矩阵中的非零数据 对于第 i 行而言，该行中非零元素的列索引为 indices[indptr[i]:indptr[i+1]] 可以将 indptr 理解成利用其自身索引 i 来指向第 i 行元素的列索引 根据[indptr[i]:indptr[i+1]]，我就得到了该行中的非零元素个数，如 若 index[i] = 3 且 index[i+1] = 3 ，则第 i 行的没有非零元素 若 index[j] = 6 且 index[j+1] = 7 ，则第 j 行的非零元素的列索引为 indices[6:7] 得到了行索引、列索引，相应的数据存放在： data[indptr[i]:indptr[i+1]] 对于矩阵第 0 行，我们需要先得到其非零元素列索引 由 indptr[0] = 0 和 indptr[1] = 2 可知，第 0 行有两个非零元素。 它们的列索引为 indices[0:2] = [0, 2] ，且存放的数据为 data[0] = 8 ， data[1] = 2 因此矩阵第 0 行的非零元素 csr[0][0] = 8 和 csr[0][2] = 2 对于矩阵第 4 行，同样我们需要先计算其非零元素列索引 由 indptr[4] = 3 和 indptr[5] = 6 可知，第 4 行有3个非零元素。 它们的列索引为 indices[3:6] = [2, 3，4] ，且存放的数据为 data[3] = 7 ，data[4] = 1 ，data[5] = 2 因此矩阵第 4 行的非零元素 csr[4][2] = 7 ， csr[4][3] = 1 和 csr[4][4] = 2 适用场景 常用于读入数据后进行稀疏矩阵计算，运算高效 优缺点 ①优点 高效的稀疏矩阵算术运算 高效的行切片 快速地矩阵矢量积运算 ②缺点 较慢地列切片操作（可以考虑CSC） 转换到稀疏结构代价较高（可以考虑LIL，DOK） 实例化 csr_matrix(D)：D代表密集矩阵； csr_matrix(S)：S代表其他类型稀疏矩阵 csr_matrix((M, N), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d， csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])) 三者关系：a[row_ind[k], col_ind[k]] = data[k] csr_matrix((data, indices, indptr), [shape=(M, N)]) 第i行的列索引存储在其中indices[indptr[i]:indptr[i+1]] 其对应值存储在中data[indptr[i]:indptr[i+1]] 特殊属性 data ：稀疏矩阵存储的值，一维数组 indices ：存储矩阵有有非零值的列索引 indptr ：类似指向列索引的指针数组 [has_sorted_indices](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.has_sorted_indices.html#scipy.sparse.bsr_matrix.has_sorted_indices)：索引 indices 是否排序 12345678910111213141516171819202122232425# 生成数据indptr = np.array([0, 2, 3, 3, 3, 6, 6, 7])indices = np.array([0, 2, 2, 2, 3, 4, 3])data = np.array([8, 2, 5, 7, 1, 2, 9])# 创建矩阵csr = sparse.csr_matrix((data, indices, indptr))# 转为arraycsr.toarray()&#x27;&#x27;&#x27;array([[1, 0, 2], [0, 0, 3], [4, 5, 6]])&#x27;&#x27;&#x27;# 按row行来压缩# 对于第i行，非0数据列是indices[indptr[i]:indptr[i+1]] 数据是data[indptr[i]:indptr[i+1]]# 在本例中# 第0行，有非0的数据列是indices[indptr[0]:indptr[1]] = indices[0:2] = [0,2]# 数据是data[indptr[0]:indptr[1]] = data[0:2] = [1,2],所以在第0行第0列是1，第2列是2# 第1行，有非0的数据列是indices[indptr[1]:indptr[2]] = indices[2:3] = [2]# 数据是data[indptr[1]:indptr[2] = data[2:3] = [3],所以在第1行第2列是3# 第2行，有非0的数据列是indices[indptr[2]:indptr[3]] = indices[3:6] = [0,1,2]# 数据是data[indptr[2]:indptr[3]] = data[3:6] = [4,5,6],所以在第2行第0列是4，第1列是5,第2列是6 CSC - csc_matrix Compressed Sparse Column Matrix 压缩稀疏列矩阵 csc_matrix是按列对矩阵进行压缩的 通过 indices, indptr，data 来确定矩阵，可以对比CSR data 表示矩阵中的非零数据 对于第 i 列而言，该行中非零元素的行索引为indices[indptr[i]:indptr[i+1]] 可以将 indptr 理解成利用其自身索引 i 来指向第 i 列元素的列索引 根据[indptr[i]:indptr[i+1]]，我就得到了该行中的非零元素个数，如 若 index[i] = 1 且 index[i+1] = 1 ，则第 i 列的没有非零元素 若 index[j] = 4 且 index[j+1] = 6 ，则第 j列的非零元素的行索引为 indices[4:6] 得到了列索引、行索引，相应的数据存放在： data[indptr[i]:indptr[i+1]] 对于矩阵第 0 列，我们需要先得到其非零元素行索引 由 indptr[0] = 0 和 indptr[1] = 1 可知，第 0列行有1个非零元素。 它们的行索引为 indices[0:1] = [0] ，且存放的数据为 data[0] = 8 因此矩阵第 0 行的非零元素 csc[0][0] = 8 对于矩阵第 3 列，同样我们需要先计算其非零元素行索引 由 indptr[3] = 4 和 indptr[4] = 6 可知，第 4 行有2个非零元素。 它们的行索引为 indices[4:6] = [4, 6] ，且存放的数据为 data[4] = 1 ，data[5] = 9 因此矩阵第 i 行的非零元素 csr[4][3] = 1 ， csr[6][3] = 9 应用场景 参考CSR 优缺点 对比参考CSR 实例化 csc_matrix(D)：D代表密集矩阵； csc_matrix(S)：S代表其他类型稀疏矩阵 csc_matrix((M, N), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d， csc_matrix((data, (row_ind, col_ind)), [shape=(M, N)])) 三者关系：a[row_ind[k], col_ind[k]] = data[k] csc_matrix((data, indices, indptr), [shape=(M, N)]) 第i列的列索引存储在其中indices[indptr[i]:indptr[i+1]] 其对应值存储在中data[indptr[i]:indptr[i+1]] 特殊属性 data ：稀疏矩阵存储的值，一维数组 indices ：存储矩阵有有非零值的行索引 indptr ：类似指向列索引的指针数组 [has_sorted_indices](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.has_sorted_indices.html#scipy.sparse.bsr_matrix.has_sorted_indices)：索引 indices 是否排序 12345678910111213141516171819202122232425# 生成数据row = np.array([0, 2, 2, 0, 1, 2])col = np.array([0, 0, 1, 2, 2, 2])data = np.array([1, 2, 3, 4, 5, 6])# 创建矩阵csc = sparse.csc_matrix((data, (row, col)), shape=(3, 3)).toarray()# 转为arraycsc.toarray()&#x27;&#x27;&#x27;array([[1, 0, 4], [0, 0, 5], [2, 3, 6]], dtype=int64)&#x27;&#x27;&#x27;# 按col列来压缩# 对于第i列，非0数据行是indices[indptr[i]:indptr[i+1]] 数据是data[indptr[i]:indptr[i+1]]# 在本例中# 第0列，有非0的数据行是indices[indptr[0]:indptr[1]] = indices[0:2] = [0,2]# 数据是data[indptr[0]:indptr[1]] = data[0:2] = [1,2],所以在第0列第0行是1，第2行是2# 第1行，有非0的数据行是indices[indptr[1]:indptr[2]] = indices[2:3] = [2]# 数据是data[indptr[1]:indptr[2] = data[2:3] = [3],所以在第1列第2行是3# 第2行，有非0的数据行是indices[indptr[2]:indptr[3]] = indices[3:6] = [0,1,2]# 数据是data[indptr[2]:indptr[3]] = data[3:6] = [4,5,6],所以在第2列第0行是4，第1行是5,第2行是6 BSR - bsr_matrix Block Sparse Row Matrix 分块压缩稀疏行格式 基于行的块压缩，与csr类似，都是通过data，indices，indptr来确定矩阵 与csr相比，只是data中的元数据由0维的数变为了一个矩阵（块），其余完全相同 块大小 blocksize 块大小 (R, C) 必须均匀划分矩阵 (M, N) 的形状。 R和C必须满足关系：M % R = 0 和 N % C = 0 适用场景及优点参考csr 实例化 bsr_matrix(D)：D代表密集矩阵； bsr_matrix(S)：S代表其他类型稀疏矩阵 bsr_matrix((M, N), [blocksize =(R,C), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d， (data, ij), [blocksize=(R,C), shape=(M, N)] 两者关系：a[ij[0,k], ij[1,k]] = data[k]] bsr_matrix((data, indices, indptr), [shape=(M, N)]) 第i行的块索引存储在其中indices[indptr[i]:indptr[i+1]] 其相应块值存储在中data[indptr[i]:indptr[i+1]] 特殊属性 data ：稀疏矩阵存储的值，一维数组 indices ：存储矩阵有有非零值的列索引 indptr ：类似指向列索引的指针数组 blocksize ：矩阵的块大小 [has_sorted_indices](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.has_sorted_indices.html#scipy.sparse.bsr_matrix.has_sorted_indices)：索引 indices 是否排序 代码示例 12345678910111213141516# 生成数据indptr = np.array([0,2,3,6])indices = np.array([0,2,2,0,1,2])data = np.array([1,2,3,4,5,6]).repeat(4).reshape(6,2,2)# 创建矩阵bsr = bsr_matrix((data, indices, indptr), shape=(6,6)).todense()# 转为arraybsr.todense()matrix([[1, 1, 0, 0, 2, 2], [1, 1, 0, 0, 2, 2], [0, 0, 0, 0, 3, 3], [0, 0, 0, 0, 3, 3], [4, 4, 5, 5, 6, 6], [4, 4, 5, 5, 6, 6]]) 优缺点 ①优点 与csr很类似 更适合于适用于具有密集子矩阵的稀疏矩阵 在某些情况下比csr和csc计算更高效。 DOK- dok_matrix Dictionary of Keys Matrix 按键字典矩阵 采用字典来记录矩阵中不为0的元素 字典的 key 存的是记录元素的位置信息的元组， value 是记录元素的具体值 适用场景 逐渐添加矩阵的元素 实例化方法 dok_matrix(D)：D代表密集矩阵； dok_matrix(S)：S代表其他类型稀疏矩阵 dok_matrix((M, N), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d， 优缺点 ①优点 对于递增的构建稀疏矩阵很高效，比如定义该矩阵后，想进行每行每列更新值，可用该矩阵。 可以高效访问单个元素，只需要O(1) ②缺点 不允许重复索引（coo中适用），但可以很高效的转换成coo后进行重复索引 代码示例 12345678910111213141516171819dok = sparse.dok_matrix((5, 5), dtype=np.float32)for i in range(5): for j in range(5): dok[i,j] = i+j # 更新元素# zero elements are accessibledok[(0, 0)] # = 0dok.keys()# &#123;(0, 0), ..., (4, 4)&#125;dok.toarray()&#x27;&#x27;&#x27;[[0. 1. 2. 3. 4.] [1. 2. 3. 4. 5.] [2. 3. 4. 5. 6.] [3. 4. 5. 6. 7.] [4. 5. 6. 7. 8.]] &#x27;&#x27;&#x27; LIL - lil_matrix Linked List Matrix 链表矩阵 使用两个列表存储非0元素data rows保存非零元素所在的列 可以使用列表赋值来添加元素，如 lil[(0, 0)] = 8 lil[(0, -1)] = 4 ：第0行的最后一列元素为4 lil[(4, 2)] = 5 ：第4行第2列的元素为5 适用场景 适用的场景是逐渐添加矩阵的元素（且能快速获取行相关的数据） 需要注意的是，该方法插入一个元素最坏情况下可能导致线性时间的代价，所以要确保对每个元素的索引进行预排序 优缺点 ①优点 适合递增的构建成矩阵 转换成其它存储方式很高效 支持灵活的切片 ②缺点 当矩阵很大时，考虑用coo 算术操作，列切片，矩阵向量内积操作慢 实例化方法 lil_matrix(D)：D代表密集矩阵； lil_matrix(S)：S代表其他类型稀疏矩阵 lil_matrix((M, N), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d 特殊属性 data：存储矩阵中的非零数据 rows：存储每个非零元素所在的列（行信息为列表中索引所表示） 代码示例 12345678910111213141516171819202122232425262728293031323334353637383940# 创建矩阵lil = sparse.lil_matrix((6, 5), dtype=int)# 设置数值# set individual pointlil[(0, -1)] = -1# set two pointslil[3, (0, 4)] = [-2] * 2# set main diagonallil.setdiag(8, k=0)# set entire columnlil[:, 2] = np.arange(lil.shape[0]).reshape(-1, 1) + 1# 转为arraylil.toarray()&#x27;&#x27;&#x27;array([[ 8, 0, 1, 0, -1], [ 0, 8, 2, 0, 0], [ 0, 0, 3, 0, 0], [-2, 0, 4, 8, -2], [ 0, 0, 5, 0, 8], [ 0, 0, 6, 0, 0]])&#x27;&#x27;&#x27;# 查看数据lil.data&#x27;&#x27;&#x27;array([list([0, 2, 4]), list([1, 2]), list([2]), list([0, 2, 3, 4]), list([2, 4]), list([2])], dtype=object)&#x27;&#x27;&#x27;lil.rows&#x27;&#x27;&#x27;array([[list([8, 1, -1])], [list([8, 2])], [list([3])], [list([-2, 4, 8, -2])], [list([5, 8])], [list([6])]], dtype=object)&#x27;&#x27;&#x27; DIA - dia_matrix Diagonal Matrix 对角存储格式 dia_matrix通过两个数组确定： data 和 offsets data ：对角线元素的值 offsets ：第 i 个 offsets 是当前第 i 个对角线和主对角线的距离 data[k:] 存储了 offsets[k] 对应的对角线的全部元素 当 offsets[0] = 0 时，表示该对角线即是主对角线，相应的值为 [1, 2, 3, 4, 5] 当 offsets[2] = 2 时，表示该对角线为主对角线向上偏移2个单位，相应的值为 [11, 12, 13, 14, 15] 但该对角线上元素仅有三个 ，于是采用先出现的元素无效的原则 即前两个元素对构造矩阵无效，故该对角线上的元素为 [13, 14, 15] 适用场景 最适合对角矩阵的存储方式 实例化方法 dia_matrix(D)：D代表密集矩阵； dia_matrix(S)：S代表其他类型稀疏矩阵 dia_matrix((M, N), [dtype])：构建一个shape为M*N的空矩阵，默认数据类型是d， dia_matrix((data, offsets)), [shape=(M, N)]))： data[k,:] 存储着对角偏移量为 offset[k] 的对角值 特殊属性 data：存储DIA对角值的数组 offsets：存储DIA对角偏移量的数组 代码示例 1234567891011121314151617181920212223242526# 生成数据data = np.array([[1, 2, 3, 4], [5, 6, 0, 0], [0, 7, 8, 9]])offsets = np.array([0, -2, 1])# 创建矩阵dia = sparse.dia_matrix((data, offsets), shape=(4, 4))# 查看数据# replace cutoff datadia.data.ravel()[9:12] = 0dia.data&#x27;&#x27;&#x27;array([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 0], [ 0, 0, 13, 14, 15]])&#x27;&#x27;&#x27;# 转为arraydia.toarray()&#x27;&#x27;&#x27;array([[1, 7, 0, 0], [0, 2, 8, 0], [5, 0, 3, 9], [0, 6, 0, 4]])&#x27;&#x27;&#x27; 矩阵格式对比 COO DOK LIL CSR CSC BSR DIA Dense indexing no yes yes yes yes no† no yes “write-only” yes yes yes no no no no yes “read-only” no no no yes yes yes yes yes low memory‡ yes no no yes yes yes yes no PyData sparse yes yes no no no no no n/a 稀疏矩阵存取 存储 - save_npz 12# 存储为npz文件scipy.sparse.save_npz(&#x27;sparse_matrix.npz&#x27;, sparse_matrix) 读取 - load_npz 12# 从npz文件中读取mat = sparse.load_npz(&#x27;./data/npz/test_x.npz&#x27;) 存储大小比较 123456789101112131415a = np.arange(100000).reshape(1000,100)a[10: 300] = 0b = sparse.csr_matrix(a)# 稀疏矩阵压缩存储到npz文件sparse.save_npz(&#x27;b_compressed.npz&#x27;, b, True) # 文件大小：100KB# 稀疏矩阵不压缩存储到npz文件sparse.save_npz(&#x27;b_uncompressed.npz&#x27;, b, False) # 文件大小：560KB# 存储到普通的npy文件np.save(&#x27;a.npy&#x27;, a) # 文件大小：391KB# 存储到压缩的npz文件np.savez_compressed(&#x27;a_compressed.npz&#x27;, a=a) # 文件大小：97KB• 1 对于存储到npz文件中的CSR格式的稀疏矩阵，内容为： 12345data.npyformat.npyindices.npyindptr.npyshape.npy 参考 Sparse matrices (scipy.sparse) Sparse Matrices python稀疏矩阵的存储与表示 python scipy 稀疏矩阵详解 SciPy教程 - 稀疏矩阵库scipy.sparse","categories":[{"name":"DA - 数据分析","slug":"DA-数据分析","permalink":"https://www.geminilight.cn/categories/DA-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.geminilight.cn/tags/Python/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://www.geminilight.cn/tags/Data-Science/"},{"name":"SciPy","slug":"SciPy","permalink":"https://www.geminilight.cn/tags/SciPy/"}],"author":"Gemini向光性"},{"title":"【PPT设计】大一大二时期个人PPT设计风格总结","slug":"GD - 平面设计/gd-ppt-conclusion-18-20","date":"2020-08-17T02:26:30.000Z","updated":"2020-11-30T07:37:07.898Z","comments":true,"path":"2020/08/17/GD - 平面设计/gd-ppt-conclusion-18-20/","link":"","permalink":"https://www.geminilight.cn/2020/08/17/GD%20-%20%E5%B9%B3%E9%9D%A2%E8%AE%BE%E8%AE%A1/gd-ppt-conclusion-18-20/","excerpt":"[更新中] 时光总若即若离，不觉将至大三。回望已逝的两年大学生活，发现自己已经做了不少的PPT，有关社团、有关学术、有关技术等等。于是，今天将两年来所作PPT汇总整理，来分析个人的风格，以寻求进步。","text":"[更新中] 时光总若即若离，不觉将至大三。回望已逝的两年大学生活，发现自己已经做了不少的PPT，有关社团、有关学术、有关技术等等。于是，今天将两年来所作PPT汇总整理，来分析个人的风格，以寻求进步。 前言 PPT设计所涉及到的结构和元素繁多，于是文章将按时间顺序分别从结构设计、元素和动画设计三方面来介绍。 结构设计 首页 2018/11/20-大计基展演 描述：这个PPT做的时间还是比较早的，当时为了契合WPS和OFFICE对比的主题，于是做的颜色和动画比较花哨 想法：颜色多而且都是重色彩的，过浓而影响视觉重心，可以减少些装饰元素未出现或不搭的颜色如粉、紫等等，再减少些颜色的饱和度，或许会改善些。 2019/06/03-SRTP立项 描述：大概是第一次复现这副封面，比较适合首页信息密度较高的构图 想法：背景颜色稍微亮了些，右部分的构图不太稳 2019/08/30-实训结题 2020/04/09-虹霖品牌咨询 2020/06/05-陈述与沟通Presentation 2020/06/24-市创立项 目录页 2019/06/03-SRTP立项 2019/08/30-实训结题 2020/06/24-市创立项 图示页 2019/06/03-SRTP立项 2019/08/30-实训结题 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 2020/06/05-陈述与沟通Presentation 2020/06/05-陈述与沟通Presentation 2020/06/24-市创立项 2020/06/24-市创立项 2020/07/09-软件综合实践结题 分点页 2019/06/03-SRTP立项 2019/08/30-实训结题 2019/08/30-实训结题 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 2020/06/24-市创立项 2020/07/09-软件综合实践结题 2020/07/09-软件综合实践结题 2020/07/09-软件综合实践结题 数据页 2019/08/30-实训结题 2019/08/30-实训结题 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 2020/04/09-虹霖品牌咨询 对比页 2018/11/20-大计基展演 2020/04/09-虹霖品牌咨询 2020/06/05-陈述与沟通Presentation 人物页 2020/04/09-虹霖品牌咨询 时间轴 2020/04/09-虹霖品牌咨询 2020/06/24-市创立项 结尾页 2019/06/03-SRTP立项 2019/08/30-实训结题 2020/04/09-虹霖品牌咨询 元素设计 配色 背景 标题 动画设计 总结","categories":[{"name":"GD - 平面设计","slug":"GD-平面设计","permalink":"https://www.geminilight.cn/categories/GD-%E5%B9%B3%E9%9D%A2%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"Slide","slug":"Slide","permalink":"https://www.geminilight.cn/tags/Slide/"}],"author":"Gemini向光性"},{"title":"【Blog】深度美化和定制Hexo和NexT方法","slug":"ST - 软件工具/st-hexo-next-custom","date":"2020-08-15T19:21:59.000Z","updated":"2020-11-30T07:29:26.232Z","comments":true,"path":"2020/08/16/ST - 软件工具/st-hexo-next-custom/","link":"","permalink":"https://www.geminilight.cn/2020/08/16/ST%20-%20%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/st-hexo-next-custom/","excerpt":"虽然我们可以搜索到许多关于Hexo博客及NexT 8主题配置和美化的教程，但是，很多文章大都聚焦于某一些常用页面的优化和定制。随着版本更迭等情况导致框架可能出现调整时，这些聚焦于某一场景的方法可能会不再适用。本文将尽可能详细描述多个场景下的hexo及nexT定制方法并且提供通用的高度自定义方案。","text":"虽然我们可以搜索到许多关于Hexo博客及NexT 8主题配置和美化的教程，但是，很多文章大都聚焦于某一些常用页面的优化和定制。随着版本更迭等情况导致框架可能出现调整时，这些聚焦于某一场景的方法可能会不再适用。本文将尽可能详细描述多个场景下的hexo及nexT定制方法并且提供通用的高度自定义方案。 简介 Hexo的NexT主题采用njk来作为HTML预处理器，使用styl来扩展css，所以可以简单的理解成 \\(html\\subset njk\\) ，\\(css \\subset styl\\)。它们扩充了相应的功能和语法支持来更加高效的架构网页，当然，我们也完全可以使用html和css的语法来美化我们的网页。 自定义CSS 如NexT 8 文档中所说， As with Data Files, you can place all custom layouts or styles in a specific location (for example: hexo/source/_data). Add the custom file to hexo/source/_data and uncomment the content under the custom_file_path section in the theme config file. 我们可以在hexo/source/_data文件夹中自定义CSS/JS文件。如果想让hexo在渲染时自动引入这些文件，我们只需在next/_config.yml，将相应文件的注释取消。 有个有趣的事情是在next主题目录文件夹下也有一个_data文件夹：hexo/theme/next/source/_data，官方没有给出具体介绍，如果我们将next/_config.yml的custom_file_path前加上theme/next也基本与hexo/source/_data目录等效，故这些不再赘述。 1234567891011121314custom_file_path: #head: source/_data/head.njk #header: source/_data/header.njk #sidebar: source/_data/sidebar.njk #postMeta: source/_data/post-meta.njk #postBodyEnd: source/_data/post-body-end.njk #footer: source/_data/footer.njk #bodyEnd: source/_data/body-end.njk #variable: source/_data/variables.styl #mixin: source/_data/mixins.styl #style: source/_data/styles.styl # 定位到 hexo/theme/next/source/_data #style: theme/nextsource/_data/styles.styl 此时，hexo再进行渲染时，也会引入这些文件，当其中的样式与默认样式冲突时，自定义样式优先级高，便会覆盖默认样式。但我们会发现，这种方式只能自动引入与上述文件重名的自定义文件，所以，我们可以将所有修改或者新添的样式写入styles.styl等文件。但是，这样的方法有些确定就是不方便管理。比如，我们打算自定义一个custom-about.styl文件来专门优化“关于”页面，这时我们就要手动的把该文件引入。有以下几种方法可供参考： 在styles.styl文件中引入 1@import &quot;custom-about.styl&quot; 在about.md文件中引入 12&lt;!-- 注意文件路径是否正确 --&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;_data/custom-about.styl&quot;&gt; 在layout.njk等其他会被自动渲染的文件中引入 1&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;_data/custom-about.styl&quot;&gt; 覆盖默认样式 我们可以在styles.styl等文件中来定义class新的样式，最简单的方式就是通过F12来查看网页资源，然后选择想要修改的元素，查看元素所带的class，然后在styles.styl中重写即可。 自定义图标 NexT的默认图标库是Font Awesome，它并不包括很多国内主流网站的图标，比如Bilibili、知乎等。但我们可以通过自定义的方式来增加对这些图标的支持。下面以Bilibili为例 下载bilibili.svg，保存到theme/next/source/images/bilibili.svg 在theme/next/source/_data/styles.styl添加样式 1234567.fab.fa-bilibili &#123; background: url(/images/bilibili.svg); background-position: 50% 75%; background-repeat: no-repeat; height: 1rem; width: 1rem;&#125; 确保已经在next/_config.xml中开启了自定义文件路径 12custom_file_path: style: source/_data/styles.styl 在next/_config.xml配置相应图标 12social: Bilibili: https:&#x2F;&#x2F;space.bilibili.com&#x2F;userid&#x2F; || fab fa-bilibili 自定义JS 类比CSS。 自定义Markdown Markdown内嵌HTML 作为标记语言，Markdown在某些场景下支持对HTML、CSS和JS的扩展，即我们可以在Markdown中写入HTML语法，甚至可以内嵌CSS和JS。以下为我的博客404页面的示例： 12345678910111213141516171819202122232425---title: 404date: 2020-01-09 13:25:01layout: falsecommit: falsepermalink: /404---&lt;html lang=&quot;zh&quot;&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt; &lt;title&gt;404&lt;/title&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/404/style.css&quot;&gt; &lt;/head&gt; &lt;body style=&quot;margin: 0px&quot;&gt; &lt;div class=&quot;container&quot;&gt;&lt;div class=&quot;row&quot;&gt;&lt;div class=&quot;col-md-6 align-self-center&quot;&gt;&lt;img src=&quot;/404/404.svg&quot;&gt;&lt;/div&gt; &lt;div class=&quot;col-md-6 align-self-center&quot;&gt; &lt;h1&gt;404&lt;/h1&gt;&lt;h2&gt;UH OH! 页面丢失&lt;/h2&gt;&lt;p&gt;您所寻找的页面不存在。你可以点击下面的按钮，返回主页。&lt;/p&gt; &lt;a href=&quot;https://www.geminilight.cn/&quot;&gt;&lt;button class=&quot;btn blue&quot;&gt;返回首页&lt;/button&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 需要注意的是，在hexo渲染时，对markdown的缩进有较高的要求。至少在我实际操作过程中，如果HTML标签前有超过4个空格的缩进，便会被渲染为全文字。 Markdown渲染外部html文件 我们也可以在外部新建一个完整的html页面，然后在md文件中引入，并加入相应标签来引入渲染 1234&lt;span style=&quot;width:100%; height:260;border:none;text-align:center&quot;&gt; &lt;iframe allowtransparency=&quot;yes&quot; frameborder=&quot;0&quot; width=&quot;100%&quot; height=&quot;88&quot; src=&quot;url&quot;&gt; &lt;/iframe&gt;&lt;/span&gt; url 指向的是独立的 HTML 文件的路径，可以直接放在我们的md文件下。 此外，为了避免html文件被编译而被嵌套主题样式，我们配置主题的_config.xml来跳过对该文件的渲染： 12345# 跳过渲染skip-render: - README.md - xxx.html # 禁止渲染xxx.html文件 - *.html # 禁止渲染所有html文件 自定义页面 不含博客框架的页面 这种类型的页面指完全自定义的，即整个页面不会出现博客的header、sidebar、footer等。比如，我们可以定制一个小游戏的404界面。这里以完全自定义的xxx页面为例，创建流程如下： 在hexo主目录文件夹下，输入命令： 1hexo new page xxx 该命令会自动在hexo/source下创建xxx/xxx.md文件夹和md文件。 编辑xxx.md，添加layout: false属性 123title: xxxtype: xxxlayout: false 设置layout: false会使hexo在渲染页面时，不自动为页面渲染基本的导航栏、侧边栏等，所以该页面需要完全自定义css和js。我们可以既可以完全在md中写js和css（并不推荐），也可以单独创建相应的JS和CSS文件再引入到md文件中，下面只对后者进行介绍。 在hexo/_data文件夹中新建js和css文件 123||-- xxx.js|-- xxx.css 在xxx.md中引入 12345&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;_data/xxx.css&quot;&gt;&lt;!-- content --&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;xxx.js&quot;&gt; 含博客框架的子页面 这种类型的页面指依赖于hexo生成的博客页面主框架，比如我们的Tags标签页、Categories分类页等。这种页面并非完全定制的，这也会带来一个优点：我们可以利用Hexo和NexT主题附带的样式和JS来制作的页面。 在hexo主目录文件夹下，输入命令： 1hexo new page xxx 同自定义css方法，可在hexo/_data编辑相应文件并引入渲染 123||-- xxx.js|-- xxx.css 总结","categories":[{"name":"ST - 软件工具","slug":"ST-软件工具","permalink":"https://www.geminilight.cn/categories/ST-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://www.geminilight.cn/tags/Blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.geminilight.cn/tags/Hexo/"}],"author":"Gemini向光性"},{"title":"【Python】with语句原理","slug":"PL - 编程语言/pl-python-with","date":"2020-08-13T16:00:00.000Z","updated":"2020-11-30T07:34:10.313Z","comments":true,"path":"2020/08/14/PL - 编程语言/pl-python-with/","link":"","permalink":"https://www.geminilight.cn/2020/08/14/PL%20-%20%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/pl-python-with/","excerpt":"在我们使用Python的时候，常使用到如下的代码块: 1234567# 文件读取with open(file, &#x27;r&#x27;) as f: # CODE BLOCK ## 梯度计算with tf.GradientTape() as g: # CODE BLOCK # 在很多场景中，使用with语句来可以让我们可以更好地来管理资源和简化代码，它可以看做是对try/finally模式的简化。它原理上是利用了上下文管理器，下文简要介绍将对其执行原理和自定义的方法。","text":"在我们使用Python的时候，常使用到如下的代码块: 1234567# 文件读取with open(file, &#x27;r&#x27;) as f: # CODE BLOCK ## 梯度计算with tf.GradientTape() as g: # CODE BLOCK # 在很多场景中，使用with语句来可以让我们可以更好地来管理资源和简化代码，它可以看做是对try/finally模式的简化。它原理上是利用了上下文管理器，下文简要介绍将对其执行原理和自定义的方法。 上下文管理器概念 上下文管理协议（Context Management Protocol） 包含方法 __enter__() 和 __exit__() ，支持该协议的对象要实现这两个方法。 上下文管理器（Context Manager） 支持上下文管理协议的对象，这种对象必须实现 __enter__() 和 __exit__() 方法。 上下文管理器定义执行with语句时要建立的运行时上下文，负责执行with语句块上下文中的进入与退出操作。 通常使用with语句调用上下文管理器，也可以通过直接调用其方法来使用。 __enter__() with语句执行时，先获取上下文管理器对象，随后调用其 __enter__() 若有 as var 语句，则将返回值赋给变量var 可以返回上下文管理器对象本身，也可以是其他相关对象 __exit__() 带有三个参数 exc_type, exc_val, exc_tb 若上下文管理器对象执行无异常，则三个参数均为 None 若发生异常，则三个参数分别为 异常类型，异常值和tracback信息 with语句执行过程 123456# EXP: 表达式# VAR: 变量名，[as VAR][可选]# BlOCK: 代码块with EXP as VAR: BLOCK 执行代码时，先执行 EXPR 语句，生成上下文管理器对象 context_manager； 获取上下文管理器的 __exit()__ 方法，并保存起来用于之后的调用； 调用上下文管理器的 __enter__() 方法，且可将返回值赋给as语句变量； 执行BLOCK中的表达式； 不管是否执行过程中是否发生了异常，执行上下文管理器的 __exit__() 方法， 执行“清理”工作，如释放资源等。 如果执行过程中没有出现异常，或者语句体中执行了语句 break / continue / return ，则以 None 作为参数调用 __exit__(None, None, None) ； 如果执行过程中出现异常，则使用sys.exc_info得到的异常信息为参数调用 __exit__(exc_type, exc_value, exc_traceback) ； 出现异常时，如果 __exit__(type, value, traceback) 返回 False ，则会重新抛出异常，让with之外的语句逻辑来处理异常，这也是通用做法；如果返回True，则忽略异常，不再对异常进行处理。 自定义上下文管理器 它使代码更简练，可以简化try/finally模式 当代码异常产生时，__exit__() 会执行清理工作 可以对软件系统中的资源进行管理，比如数据库连接、共享资源的访问控制等 12345678910111213141516171819202122232425262728293031323334# coding = utf-8# 上下文管理器类class TestWith(object): def __init__(self): pass def __enter__(self): &quot;&quot;&quot;进入with语句的时候被调用 并将返回值赋给as语句的变量名 &quot;&quot;&quot; print(&#x27;__enter__&#x27;) return &quot;var&quot; def __exit__(self, exc_type, exc_val, exc_tb): &quot;&quot;&quot;离开with的时候被with调用&quot;&quot;&quot; print(&#x27;__exit__&#x27;) return True# with后面必须跟一个上下文管理器# 如果使用了as，则是把上下文管理器的 __enter__() 方法的返回值赋值给 target# target 可以是单个变量，或者由“()”括起来的元组（不能是仅仅由“,”分隔的变量列表，必须加“()”）if __name__ = &#x27;main&#x27;: with TestWith() as var: print(var)# 运行结果&#x27;&#x27;&#x27;__enter__var__exit__&#x27;&#x27;&#x27; 本例仅对应代码正常执行的流程，其他特殊情况不再一一列举，有兴趣可单独实验。 参考 浅谈 Python 的 with 语句 Python中with用法详解 Python中with使用","categories":[{"name":"PL - 编程语言","slug":"PL-编程语言","permalink":"https://www.geminilight.cn/categories/PL-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.geminilight.cn/tags/Python/"}],"author":"Gemini向光性"},{"title":"【论文笔记】Automatic Virtual Network Embedding - A DRL Approach with GCN","slug":"RP - 科研论文/paper-nfv-vne-rl-gcn","date":"2020-07-12T16:00:00.000Z","updated":"2020-11-30T14:06:32.653Z","comments":true,"path":"2020/07/13/RP - 科研论文/paper-nfv-vne-rl-gcn/","link":"","permalink":"https://www.geminilight.cn/2020/07/13/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/paper-nfv-vne-rl-gcn/","excerpt":"本篇论文将强化学习A3C算法与图卷积神经网络GCN相结合，并且设置了多目标的奖励函数，提出了一种更加高效的虚拟网络嵌入算法。 论文简介 论文名称：Automatic Virtual Network Embedding: A Deep Reinforcement Learning Approach with Graph Convolutional Networks 论文作者：Zhongxia Yan, Jingguo Ge, Y ulei Wu, Senior Member , IEEE, Liangxiong Li, Tong Li 发表期刊：JSAC-2020 (CCF-A) 研究方向：NFV 网络功能虚拟化 关键技术：虚拟网络嵌入, 强化学习, 图卷积神经网络 主要创新：强化学习结合图卷积神经网络、并行的强化学习框架、多目标的奖励函数 下载论文","text":"本篇论文将强化学习A3C算法与图卷积神经网络GCN相结合，并且设置了多目标的奖励函数，提出了一种更加高效的虚拟网络嵌入算法。 论文简介 论文名称：Automatic Virtual Network Embedding: A Deep Reinforcement Learning Approach with Graph Convolutional Networks 论文作者：Zhongxia Yan, Jingguo Ge, Y ulei Wu, Senior Member , IEEE, Liangxiong Li, Tong Li 发表期刊：JSAC-2020 (CCF-A) 研究方向：NFV 网络功能虚拟化 关键技术：虚拟网络嵌入, 强化学习, 图卷积神经网络 主要创新：强化学习结合图卷积神经网络、并行的强化学习框架、多目标的奖励函数 下载论文 问题定义 专业词汇 缩写 描述 全名 VNE 虚拟网络嵌入 Virtual Network Embedding VNR 虚拟网络请求 Virtual Network Request RL 强化学习 Reinforcement Learning GCN 图卷积神经网络 Graph Convolutional Network A3C Asynchronous Advantage Actor-Critic VNE 算法模型 DL-A3C GCN A3C + GCN 环境 Environment 代理 Agent 状态 State 动作 Action 奖励 Rewords 动作反馈 action feedback \\[r_{a}=\\left\\{\\begin{array}{cl} 100 \\gamma_{a} &amp; a_{t} \\text {is successful} \\\\ -100 \\gamma_{a} &amp; \\text {otherwise} \\end{array}\\right.\\] 成本效益 cost-efficient \\[r_{c} = \\frac{\\delta(revenue)}{\\delta(cost)}\\] 负载均衡 Load balancing \\[r_{s} = \\frac{S_CPU_Remaining[a]}{S_CPU_Max[a]}\\] 资格痕迹 eligibility trace \\[e g b_{-}{trace}_{t}[i]=\\left\\{\\begin{array}{cl} \\gamma_{e}\\left(e g b_{-}{trace}_{t-1}[i]+1\\right) &amp; i==a_{t} \\\\ \\gamma_{e} {egb}_{-} {trace}_{t-1}[i] &amp; \\text { otherwise } \\end{array}\\right.\\] 故最终对于动作\\(a{t}\\)奖励函数（Reward Function）为 \\[Reward[a_{t}]=\\frac{r_{a} r_{c} r_{s}}{e g b{-}trace[a_{t}]+\\epsilon}\\] 性能评估 设计实验 底层网络拓扑 使用参数 \\(\\alpha = 0.5\\) 和 \\(\\beta = 0.2\\) 的 Waxman 随机图来生成一个底层网络拓扑 该网络具有100个结点和500条边（模拟一个中型的ISP）。 随机分配每个节点的CPU数量和边的带宽大小为50~100个单位。 虚拟网络请求 随机生成VNR时满足Possion process（泊松分布），每组评估持续50000个时间单位 即当VNR预期到达率为4个/100个时间单位时，则约有2000个VNR 每个VRN的生成周期满足平均值为500的指数分布 每个VNR的数量均匀分布在2~10之间 初始化VNR中的节点CPU需求和链路带宽需求为0~30的均匀分布 每对节点有50%的可能性形成边 动态设置参数 VNR的到达率、节点及链路资源的分配、每个VNR的节点数量 我们可以通过调节这三个参数来评估各种VNE场景 测试阶段 学习代理仅使用actor网络生成嵌入策略，来从底层网络拓扑中选择合适的节点托管当前的虚拟节点 该代理已被训练72小时，经历了70000次训练迭代，进行了近1680000次不同的VNR 对比算法 R-ViNE 使用基于确定的取整（rounding-based）的方法来获得与VNE问题对应的MIP的线性规划松弛（linear programming relaxation），以最小化VNR的成本 D-ViNE 和RR-ViNE，但特殊在其取整方法是随机的 GRC 一种基于全局资源容量管理的节点排序算法 MCVNE 一种基于强化学习的 Monte-Carlo MCTS 动作空间搜索算法 NodeRank 一种节点排序算法，灵感来自与Google的PageRank算法 它们基本覆盖了当前大部分算法的观点 评估指标 VNR 到达率测试 实际场景：虚拟网络总在忙碌时频繁接受VNR请求，空闲时则反之。 实验模拟：将到达率由4个/100时间单位逐渐增至20个/100时间单位，步长为2。 结果分析：该算法在VNR请求较频繁时，接受率和平均收益明显优于其他算法。 资源请求测试 实际场景：不同的网络服务具有不同的资源需求模式，比如： 计算密集型任务需要更多的节点资源（CPU） 而通信密集型任务需要更多的链路资源（带宽） 实验模拟：将节点与链路资源需求的逐渐由[0,30]升至[0,100]的平均分布，步长为10。 结果分析：随着资源需求越来越多，嵌入的成功率也会都明显随之降低，但该算法的表现依然是最忧的。 节点数量扩展性测试 实际场景：企业级用户对网络服务需求量较大，个人用户服务使用的节点数量较小。 实验模拟：将VNR中的虚拟节点数量从[2,10]的均匀分布增加到[2,32]，步长为2。 结果分析：该算法优势明显，但可以发现当节点逐渐增加时，接受率下降明显 原因分析： 因为每个VNR都必须作为一个整体成功地嵌入；一个更大的VNR意味着在嵌入的中间步骤中失败的机会更多； 因为同一VNR中的两个虚拟节点不能共享一个特定的基板节点，单个VNR中的更多节点限制了候选动作空间 平均运行时间统计 平均运行时间指VNE算法处理一个完整VNF的平均时间开销 验证测试 在相同条件下，与其他基于强化学习的VNE算法进行比较 训练效率及收敛性 不同算法在相同实验条件下的训练效果对比，见下图(a) 实验结果：可以发现，在这组实验中，平均收益的优势要比接受率的明显 原因分析：当VNR的节点数量较少时，所有算法都可以有很好的表现；但当节点增多后，该算法可以带来更多的潜在收益（多指标的Reward）。 资源请求测试验证 在不同的资源请求情况下，对这些算法进行测试，见下图(b) 实验结果：在不同数量的资源请求情况下，该算法的接受率均是最优的；此外，可以发现CNN的性能表现始终是最差的 原因分析：用GCN代替传统的CNN进行特征提取可以带来更好地性能。 其他参数下模型的可行性研究 附加网络拓扑和参数 CSTNET：中国网络运营商，见下图(a) 红色边为100Gb带宽的链路 绿色边为10Gb带宽的链路 橙色边为2.5Gb带宽的链路 黑色边为1Gb带宽的链路 边的权重：平均传输延迟 average transmission latency（毫秒）， 对比算法：Noderank 实验设计： 模拟了一些随机的点对点的数据传输任务 数据传输速率为 [500Mbps,3Gbps] 的均匀分布 实验结果：A3C+GCN 模型的延迟更少 其他指标 节点资源利用率：VNRs使用的节点基板资源量/资源总量 链路资源利用率：VNRs使用的链路基板资源量/资源总量 实验设计：同平均到达率测试 实验结果：A3C+GCN算法的这两项指标均为最佳 主要创新 基于RL+GCN的自动虚拟网络嵌入算法 并行的策略梯度训练方法 多指标的奖励函数 总结思考 GCN较CNN可以更好地提取非欧数据的特征 A3C算法较其他RL算法性能表现更佳 并行的梯度训练策略更适应于实际场景 多指标的Reward可以让Agent学习到更好地策略来提高收益 在模型评估部分，实验的设计比较完善","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"GNN","slug":"GNN","permalink":"https://www.geminilight.cn/tags/GNN/"},{"name":"Paper","slug":"Paper","permalink":"https://www.geminilight.cn/tags/Paper/"},{"name":"NFV","slug":"NFV","permalink":"https://www.geminilight.cn/tags/NFV/"},{"name":"DRL","slug":"DRL","permalink":"https://www.geminilight.cn/tags/DRL/"}],"author":"Gemini向光性"},{"title":"【学术讲座】ZJU 陈为教授：大数据与可视化技术","slug":"RP - 科研论文/lecture-zju-professor-chenwei-date-visonlization","date":"2020-03-21T06:43:00.000Z","updated":"2020-12-01T14:28:51.929Z","comments":true,"path":"2020/03/21/RP - 科研论文/lecture-zju-professor-chenwei-date-visonlization/","link":"","permalink":"https://www.geminilight.cn/2020/03/21/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/lecture-zju-professor-chenwei-date-visonlization/","excerpt":"浙江大学陈为教授关于大数据与可视化技术及其应用的讲座。","text":"浙江大学陈为教授关于大数据与可视化技术及其应用的讲座。 大数据思维 一、数据核心原理 从“流程”核心转变为“数据”核心 二、数据价值原理 由功能即价值转变为数据即价值 三、全样本原理 从抽样转变为需要全部数据样本 四、关注效率原理 由关注精确度转变为关注效率 五、利用相关性取代因果关系 不需要知道为什么 六、从采样到全样本 抽样 != 全样 七、从精确到模糊 大数据简单算法比小数据复杂性算法更有效 八、安迪·比尔定律 软件硬件相互要求 大数据时代生产越来越过剩 大数据分析应用的三个层次 描述性分析-&gt; 预测性分析 -&gt; 指导性分析 关注发生了什么，呈现事物 关注“可能发生什么”，呈现趋势 关注“选择做什么”，呈现不同决策的后果 数据可视化 概念原理 创建并研究数据的视觉表达 (Visual Representation) 输入：数据（data） 输出：视觉形式（visual form） 目标：深入理解（insight） 主要任务 表示数据 - Represent 分析数据 - Analyze 交流数据 - Communicate 思维系统 重要应用 科学研究 Screenshot_2020-03-21-19-29-04-321_com.tencent.mm.jpg 物联网与智慧城市 Screenshot_2020-03-21-19-31-43-189_com.tencent.mm.jpg Screenshot_2020-03-21-19-31-00-805_com.tencent.mm.jpg Screenshot_2020-03-21-19-32-44-746_com.tencent.mm.jpg 互联网与社交媒体 Screenshot_2020-03-21-19-33-59-913_com.tencent.mm.jpg 可视化战役 Screenshot_2020-03-21-19-22-01-271_com.tencent.mm.jpg 可视化技术原理 Screenshot_2020-03-21-19-36-29-829_com.tencent.mm.jpg Screenshot_2020-03-21-19-38-51-711_com.tencent.mm.jpg Screenshot_2020-03-21-19-39-35-005_com.tencent.mm.jpg Screenshot_2020-03-21-19-41-55-010_com.tencent.mm.jpg Screenshot_2020-03-21-19-43-19-126_com.tencent.mm.jpg 疫情可视化成果 Screenshot_2020-03-21-19-43-50-613_com.tencent.mm.jpg Screenshot_2020-03-21-19-46-02-513_com.tencent.mm.jpg Screenshot_2020-03-21-19-46-10-852_com.tencent.mm.jpg Screenshot_2020-03-21-19-47-49-742_com.tencent.mm.jpg Screenshot_2020-03-21-19-48-35-127_com.tencent.mm.jpg Screenshot_2020-03-21-19-50-08-299_com.tencent.mm.jpg Screenshot_2020-03-21-19-52-23-743_com.tencent.mm.jpg Screenshot_2020-03-21-19-55-31-803_com.tencent.mm.jpg 疫情可视化公益活动 Screenshot_2020-03-21-19-55-47-774_com.tencent.mm.jpg Screenshot_2020-03-21-20-04-33-705_com.tencent.mm.jpg Screenshot_2020-03-21-20-08-01-604_com.tencent.mm.jpg Screenshot_2020-03-21-20-11-09-734_com.tencent.mm.jpg 拓展阅读 浙江大学陈为“大数据可视化” 彻底颠覆你认知的10条大数据思维 我的心得","categories":[{"name":"MY - 感悟随笔","slug":"MY-感悟随笔","permalink":"https://www.geminilight.cn/categories/MY-%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Research","slug":"Research","permalink":"https://www.geminilight.cn/tags/Research/"},{"name":"Data Visualization","slug":"Data-Visualization","permalink":"https://www.geminilight.cn/tags/Data-Visualization/"}],"author":"Gemini向光性"},{"title":"【科研思维】高效的机器学习研究者","slug":"RP - 科研论文/research-effictive-ml-researcher","date":"2020-02-24T16:00:00.000Z","updated":"2020-11-30T07:28:51.158Z","comments":true,"path":"2020/02/25/RP - 科研论文/research-effictive-ml-researcher/","link":"","permalink":"https://www.geminilight.cn/2020/02/25/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/research-effictive-ml-researcher/","excerpt":"△ 高效的机器学习研究者 | 彻底的自我管理能力 + 坚持到底的决心 ☆ John Schulman &amp; 吴恩达","text":"△ 高效的机器学习研究者 | 彻底的自我管理能力 + 坚持到底的决心 ☆ John Schulman &amp; 吴恩达 笔记 1. 挑选研究问题 （1）提升研究品位 阅读论文 - 认真评论与探讨 研究小组 - 吸收他人研究经验 同行建议 - 吸收他人的看法 成果产出 - 思考最有可能产出成果的研究方向/问题 （2）研究的原动力 想法驱动 - 测试某些想法 深刻理解研究主题以获得更多突破，避免与其他研究者想法相似 目标驱动 - 实现某些功能 注重通用性，将自己定义在通用解决方案中 △ 任何领域的机器学习的新想法都与某些目标有关 （3）研究目标高远 10% 的改善 OR 10 倍的提升？ 较大的目标下：增量研究（10% 的提升）是最有效的 增加的复杂性：取决于增量研究的性能提升 2. 研究是条旅途 在不清楚终点的旅途中，不断朝着更好地结果前进： （1）记录笔记 每日总结 &amp; 每周总结 = 事情 + 想法 + 成果 记录想法 整理收获 时间管理 （2）是否换坑？ 过于频繁地切换想法比呆在原地不动的故障概率更高 可以设置固定的时间去尝试那些新想法以拓宽知识面 3. 发展目光长远 走出舒适区，充实机器学习领域知识 教材书： 集中的方式来吸取知识，巩固基础 学位论文：了解研究方向的背景、现状和展望 前沿论文：关注领域前沿，并自己复现对比 4. 读论文的建议 （1）阅读进度法 每一篇列一行，表示从 0 到 100 的阅读进度 很重要：仔细读到进度100% 不想要：10%确定是否放弃阅读 （2）多次浏览法 第一遍 标题、摘要和图表 - 论文讲什么 第二遍 前言、结语和图表 - 论文主要思想 第三遍 纵览论文主体 - 把握整体脉络（数学推导可跳过） 第四遍 阅读所有内容 - 遇难可跳过以后攻坚 5. 团队合作 多与同学/同事交流 途径：向他们解释不理解的观点或算法，并说明自己尝试做的东西 目的：更容易地发现错误和潜在问题，吸收其他人提出的想法 我的收获 研究方向和问题的确定是研究的第一步，选择合适且“有品位”的问题 确定了研究目标就要坚持不懈地阅读和实验，且实验的想法和目标很重要 要培养有效的研究习惯，如记好笔记、坚持不懈等 目标长远，走出舒适区，丰富领域各方面知识 论文阅读要讲求阅读方法以提高研究效率 研究不是单打独斗，要注重团队合作，从团队交流中收获新的想法 来源： 机器之心公众号","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"Research","slug":"Research","permalink":"https://www.geminilight.cn/tags/Research/"},{"name":"ML","slug":"ML","permalink":"https://www.geminilight.cn/tags/ML/"}],"author":"Gemini向光性"},{"title":"【学术讲座】潘复生院士谈科学创新","slug":"RP - 科研论文/lecture-academician-pan-fu-sheng","date":"2019-09-22T06:43:00.000Z","updated":"2020-11-30T07:37:47.102Z","comments":true,"path":"2019/09/22/RP - 科研论文/lecture-academician-pan-fu-sheng/","link":"","permalink":"https://www.geminilight.cn/2019/09/22/RP%20-%20%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/lecture-academician-pan-fu-sheng/","excerpt":"重庆大学材料学院潘复生院士关于科学创新的讲座","text":"重庆大学材料学院潘复生院士关于科学创新的讲座 科学发展现状 资源匮乏 信息科技依赖 生物科学 学科交叉对知识要求越来越高 我国发展现状 16个重大专项 科技实力低于美国 科技投入远低于发达国家 基础研究待加强 科学素养低（官员政策制定）科普 创新素质培养 学会合作 团结他人（比自己优秀的和略差与自己的） 学会放弃 （选择自己最喜欢的方向） 学会学习 （ 知识学习能力远比知识记忆或积累能力更重要 学习能力比死记硬背更重要 基本工具一定要好（英语，计算机） 学会忘记有时比学会记住更重要 ） 学会分析和怀疑+提问问题 （不鼓励小中学生瞎猜怀疑=》知识积累+理解世界） 大学生学会怀疑 学会表达 （让他人理解，好的表达扬长避短，站在对方角度来表达） 科研技巧 重视偶然性才有必然性 交流和讨论（潘与汉诺丁-英欧支持+国家支持） 仿生学（创新启示） 做多数人喜欢的事情（做好不喜欢的事，做自己喜欢的事做的会更好） 逆向思维是成功的捷径 我的感悟","categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"Research","slug":"Research","permalink":"https://www.geminilight.cn/tags/Research/"},{"name":"Lecture","slug":"Lecture","permalink":"https://www.geminilight.cn/tags/Lecture/"},{"name":"Innovatation","slug":"Innovatation","permalink":"https://www.geminilight.cn/tags/Innovatation/"}],"author":"Gemini向光性"},{"title":"数据分析知识体系","slug":"DA - 数据分析/da-introduction","date":"2019-08-22T02:08:11.000Z","updated":"2020-11-30T07:36:51.634Z","comments":true,"path":"2019/08/22/DA - 数据分析/da-introduction/","link":"","permalink":"https://www.geminilight.cn/2019/08/22/DA%20-%20%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/da-introduction/","excerpt":"数据分析","text":"数据分析 数据分析 Python模块 Numpy pandas Scipy matplotlib test","categories":[{"name":"DA - 数据分析","slug":"DA-数据分析","permalink":"https://www.geminilight.cn/categories/DA-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.geminilight.cn/tags/Python/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://www.geminilight.cn/tags/Data-Science/"}],"author":"Gemini向光性"},{"title":"深度学习知识体系","slug":"ML - 机器学习/dl-introduction","date":"2019-08-22T02:08:11.000Z","updated":"2020-12-01T01:40:31.930Z","comments":true,"path":"2019/08/22/ML - 机器学习/dl-introduction/","link":"","permalink":"https://www.geminilight.cn/2019/08/22/ML%20-%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/dl-introduction/","excerpt":"深度学习","text":"深度学习 基础网络 CNN RNN GNN 应用场景 CV 计算机视觉 NLP 自然语言处理 KG 知识图谱 主流框架 TensorFlow PyTorch PaddlePaddle MindSpore","categories":[{"name":"ML - 机器学习","slug":"ML-机器学习","permalink":"https://www.geminilight.cn/categories/ML-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://www.geminilight.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"author":"Gemini向光性"},{"title":"【NumPy】入门","slug":"DA - 数据分析/da-numpy","date":"2019-08-18T16:00:00.000Z","updated":"2020-11-30T07:36:45.016Z","comments":true,"path":"2019/08/19/DA - 数据分析/da-numpy/","link":"","permalink":"https://www.geminilight.cn/2019/08/19/DA%20-%20%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/da-numpy/","excerpt":"NumPy","text":"NumPy 数据 Python语言诞生后，开发人员就产生了数值计算的需求，科学社区开始考虑用它进行科学计算。 2006年，Travis Oliphant发布了NumPy库的第一个版本，整合了Numeric与Numarray包。 如今，Numpy广泛应用于计算多维数组和大型数组等方面。此外，它还提供多个函数，操作起数组来效率很高，还可用来实现高级数学运算。 当前，NumPy是开源项目，使用BSD许可证。 Numpy &amp; pandas NumPy是用Python进行科学计算，尤其是数据分析时，所用到的一个基础库。 它是大量Python数学和科学计算包的基础，比如pandas库就用到了NumPy。 pandas库专门用于数据分析，充分借鉴了Python标准库NumPy的相关概念。 Numpy的安装 Windows： pip install numpy 若下载慢导致失败，可指定国内pip源（加上-i参数，指定pip源） pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple 导入Numpy模块 &gt;&gt;&gt; import numpy as np","categories":[{"name":"DA - 数据分析","slug":"DA-数据分析","permalink":"https://www.geminilight.cn/categories/DA-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.geminilight.cn/tags/Python/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://www.geminilight.cn/tags/Data-Science/"},{"name":"NumPy","slug":"NumPy","permalink":"https://www.geminilight.cn/tags/NumPy/"}],"author":"Gemini向光性"},{"title":"Start the Journey of My Blog","slug":"MY - 感悟随笔/my-start-my-blog","date":"2019-08-02T16:00:00.000Z","updated":"2020-08-25T17:10:53.371Z","comments":true,"path":"2019/08/03/MY - 感悟随笔/my-start-my-blog/","link":"","permalink":"https://www.geminilight.cn/2019/08/03/MY%20-%20%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/my-start-my-blog/","excerpt":"Welcome to My Blog Gemini向光性 困在双子星座的流浪旅人 了解更多","text":"Welcome to My Blog Gemini向光性 困在双子星座的流浪旅人 了解更多 Involved Fields 博客计划主要涉及以下内容： 技术 机器学习：传统机器学习、深度学习、强化学习 数据分析：Numpy、Pandas、Scipy、Matlibplot 全栈开发：Vue、jQuery、MySQL、SpringBoot、Django 编程语言：Python、C/C++、Java、JS/TS 金融 宏观经济 微观经济 企业分析 金融分析 设计 PPT设计 平面设计 视频剪辑 生活 随笔 音乐 摄影 影视 游戏 烹饪 但深知自己才疏博浅且臻爱原创，又不愿随波逐流，故更新进度随缘。","categories":[{"name":"MY - 感悟随笔","slug":"MY-感悟随笔","permalink":"https://www.geminilight.cn/categories/MY-%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://www.geminilight.cn/tags/Blog/"},{"name":"随笔","slug":"随笔","permalink":"https://www.geminilight.cn/tags/%E9%9A%8F%E7%AC%94/"}],"author":"Gemini向光性"},{"title":"【Python】基础语法总结","slug":"PL - 编程语言/pl-python-fundamental-syntax","date":"2019-01-11T14:03:00.000Z","updated":"2020-11-30T07:30:48.892Z","comments":true,"path":"2019/01/11/PL - 编程语言/pl-python-fundamental-syntax/","link":"","permalink":"https://www.geminilight.cn/2019/01/11/PL%20-%20%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/pl-python-fundamental-syntax/","excerpt":"","text":"","categories":[{"name":"PL - 编程语言","slug":"PL-编程语言","permalink":"https://www.geminilight.cn/categories/PL-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.geminilight.cn/tags/Python/"}],"author":"Gemini向光性"},{"title":"【游戏人生】双子Gemini——我们都在寻找着某个人","slug":"GL - 游戏人生/game-gemini","date":"2017-08-06T16:19:26.000Z","updated":"2020-11-30T07:35:51.411Z","comments":true,"path":"2017/08/07/GL - 游戏人生/game-gemini/","link":"","permalink":"https://www.geminilight.cn/2017/08/07/GL%20-%20%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/game-gemini/","excerpt":"“我们都在寻找着 某个人”——《你的名字。》 暗夜中的荧树依旧沉睡着，它已经很久很久没有发过光了，久的人们都早已忘记了那个传说......","text":"“我们都在寻找着 某个人”——《你的名字。》 暗夜中的荧树依旧沉睡着，它已经很久很久没有发过光了，久的人们都早已忘记了那个传说...... 一、相遇：前尘如是 少了星光的装点，夜空暗淡了许多。我心有所念地张望着四周，却又不知在找寻着谁。明明毫无目的地来这儿，却又诚惶诚恐地害怕着错过。空荡荡的心将无神的目光映向不远处沉眠的荧树，然后莫名其妙地叹息。准备离开时的回眸，让我们的目光在朦胧的暮色下交错，我似乎懂了，懂得了命运织缠的意义。 时间放佛在那一刻停格，空气也随之凝滞，任由荧树的年轮刻录下心动和心悸： 你尚未出现时，我的生命平静，轩昂阔步行走，动辄料事如神；如今惶乱，怯弱，像冰融的春水，一流就流向你，又不知你在何处（木心）。可明明你就在我面前，我却又不知所措。 空气不再沉默——似乎有种引力牵引着我慢步走向了你。脚步声在寂寥的夜空中徘徊，你退回荧树枝下，等候着我的到来。但当手被牵起时，你却皱了皱眉，有些许心痛，却又不知痛从何而来。彼此只手相依，只手迎风，曼舞空凉。执子之手，挥洒荧光。古树开始苏醒，重现荧光，夜空渐被点亮，直至整个银河宛若天堂。 二、别离：心恸幽思 面前是无数陨石阻隔，彼岸即是梦寐以求的星河。无数次的碰撞，无数次的跌倒，无数次的逃亡。看着身旁遍体鳞伤的你，我心如刀割。头脑开始眩晕，身体开始麻木，但始终未停止撞击。终于，你，停了下来，慢慢下坠。此时，我，早已泪眼婆娑，椎心泣血。抱紧昏倒的你，看着你迂回的伤痕，痛恨自己的无力。 恸哭一声——微光亦可昼亮，化作流星花火，划破无边银河。天空被渲染成晨曦般的颜色，陨石被狠狠撞碎坠落，星际被灿烂夺去轮廓。我回首望向了你，微笑着轻抚了一下，拭去你眼角的泪花。凝视着你，沉默，却又更多话语。回顾此生，路途虽险，却不惧混沌黑夜，不畏疾风骤雨，只因有你相伴左右，不曾离弃。 原谅我，不再陪你，望这最后一星余晖燃尽守护你； 失去我，日月如常，世上最美的星云就在前方； 答应我，生活下去，未来你会有更好的相遇。 星辉殆尽，堙灭散落，银河再归混沌，我已一别永年。就这样，我离开了你，无声无息，了无痕迹。 三、追忆：念旧顾逝 最后一丝星火被黑夜淹没，前方不再有陨石阻隔，她向前扑去，想要如往常般依偎着他，却痛痛地跌倒在地。眼泪肆意挥霍着，润湿了瞳孔，模糊了每个角落；打在了心口，放任痛楚清晰地游走，倒带往昔彼此依偎的甜蜜： 荧树下他许诺让她看到世间最美的星云，带她浪迹天涯。 黎明的曙光照亮孤寂的夜空，驱赶着不羁的黑暗，他们双手相牵，追赶着晨曦，一起见证日出的那一抹微光。正午的太阳愈渐熠亮，他们在风中嬉戏，在路旁依靠，感受着对方的呼吸，心透着无声的默契。黄昏悄悄降临，彩霞中奔跑的身影停下了脚步，最浪漫不过彼此并肩欣赏夕阳。 时而细雨微作，他们轻歌慢步；时而骤风忽起，他们依偎拥抱。他们在文明废墟中相伴而游，见证希望；在极地冰川中相依而行，战克风霜；在富丽殿堂中相视而笑，共享荣光。音符弹奏着甜蜜，图腾印刻下笑容。 日出日落，朝暮共同分享，无惧颠簸跌宕； 路途遥远，同游山高水长，风景彼此共赏。 而这一切已成过往…… 四、辉煌：星夜如斯 任何一种环境或一个人，初次见面就预感到离别的隐痛时，你必定是爱上他了。（黄永玉）她明白了初遇时的心悸，不是青涩，亦不是恐惧，而是她早已预见他们命中注定要分离。 霓虹渐显倪端，微光开始蔓延，泪花随风飘落，伊人难以忘怀。星光映在她的脸庞，尽是泪行。手紧紧的攥着，慢步向前，她的眼神中少了悲伤，多了空灵，即使面前魂牵梦绕的星云也扬不起她嘴角的一丝微笑。 景虽美，光虽亮，可，泪已尽，心已灰。 没有形单影只的倾诉，没有感天动地的恸哭，甚至没有了恋人别离的苦楚，她走向星云的中央，目光死死的盯着他星辉散尽的方向，双臂展开，静静释怀…… 混沌银河骤然生光，星云再次燃起辉亮——她竭尽星辉在祈愿，不求时间重返，只求来世重逢。那一刻，宇宙听到了她的心声，苍穹为之感染。夜空灰暗千年，不再寂寥，星辉绚丽，占据每一寸黑暗。她最后一次俯瞰世间，不再有任何羁绊，微微一笑，随风消散。 周边的星辰说那是他们一生中见过的最美最亮的星辉：冰冷中透着暖意，凄美却又不失灿烂，那不是悲伤，而是诠释，是渴盼，是希望。 言语停了下来，荧树又重归于暗淡... ... 五、来世：情缘何去 银河浩渺无垠，星辰繁若樱花，来生相距光年十万，抑或咫尺之遥，可否会重逢再会？如若他日于星海偶遇，你我会擦肩而过，彼此不识，还是会心动如昔，情缘再续？ 命运最神秘的不是变幻莫测无人知晓，而是冥冥之中自有定向。 荧树沉寂了万年，传说不再被流传，但至今仍会有人说： 一次告别 天上就会有颗星 又熄灭","categories":[{"name":"MY - 感悟随笔","slug":"MY-感悟随笔","permalink":"https://www.geminilight.cn/categories/MY-%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Game","slug":"Game","permalink":"https://www.geminilight.cn/tags/Game/"},{"name":"Sentiment","slug":"Sentiment","permalink":"https://www.geminilight.cn/tags/Sentiment/"}],"author":"Gemini向光性"}],"categories":[{"name":"RP - 科研论文","slug":"RP-科研论文","permalink":"https://www.geminilight.cn/categories/RP-%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87/"},{"name":"WD - 网站开发","slug":"WD-网站开发","permalink":"https://www.geminilight.cn/categories/WD-%E7%BD%91%E7%AB%99%E5%BC%80%E5%8F%91/"},{"name":"MY - 感悟随笔","slug":"MY-感悟随笔","permalink":"https://www.geminilight.cn/categories/MY-%E6%84%9F%E6%82%9F%E9%9A%8F%E7%AC%94/"},{"name":"DA - 数据分析","slug":"DA-数据分析","permalink":"https://www.geminilight.cn/categories/DA-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"GD - 平面设计","slug":"GD-平面设计","permalink":"https://www.geminilight.cn/categories/GD-%E5%B9%B3%E9%9D%A2%E8%AE%BE%E8%AE%A1/"},{"name":"ST - 软件工具","slug":"ST-软件工具","permalink":"https://www.geminilight.cn/categories/ST-%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"},{"name":"PL - 编程语言","slug":"PL-编程语言","permalink":"https://www.geminilight.cn/categories/PL-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"ML - 机器学习","slug":"ML-机器学习","permalink":"https://www.geminilight.cn/categories/ML-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"DL","slug":"DL","permalink":"https://www.geminilight.cn/tags/DL/"},{"name":"GNN","slug":"GNN","permalink":"https://www.geminilight.cn/tags/GNN/"},{"name":"Paper","slug":"Paper","permalink":"https://www.geminilight.cn/tags/Paper/"},{"name":"NFV","slug":"NFV","permalink":"https://www.geminilight.cn/tags/NFV/"},{"name":"DRL","slug":"DRL","permalink":"https://www.geminilight.cn/tags/DRL/"},{"name":"Research","slug":"Research","permalink":"https://www.geminilight.cn/tags/Research/"},{"name":"front-end","slug":"front-end","permalink":"https://www.geminilight.cn/tags/front-end/"},{"name":"Web","slug":"Web","permalink":"https://www.geminilight.cn/tags/Web/"},{"name":"Blog","slug":"Blog","permalink":"https://www.geminilight.cn/tags/Blog/"},{"name":"随笔","slug":"随笔","permalink":"https://www.geminilight.cn/tags/%E9%9A%8F%E7%AC%94/"},{"name":"Python","slug":"Python","permalink":"https://www.geminilight.cn/tags/Python/"},{"name":"Data Science","slug":"Data-Science","permalink":"https://www.geminilight.cn/tags/Data-Science/"},{"name":"SciPy","slug":"SciPy","permalink":"https://www.geminilight.cn/tags/SciPy/"},{"name":"Slide","slug":"Slide","permalink":"https://www.geminilight.cn/tags/Slide/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.geminilight.cn/tags/Hexo/"},{"name":"Data Visualization","slug":"Data-Visualization","permalink":"https://www.geminilight.cn/tags/Data-Visualization/"},{"name":"ML","slug":"ML","permalink":"https://www.geminilight.cn/tags/ML/"},{"name":"Lecture","slug":"Lecture","permalink":"https://www.geminilight.cn/tags/Lecture/"},{"name":"Innovatation","slug":"Innovatation","permalink":"https://www.geminilight.cn/tags/Innovatation/"},{"name":"深度学习","slug":"深度学习","permalink":"https://www.geminilight.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"NumPy","slug":"NumPy","permalink":"https://www.geminilight.cn/tags/NumPy/"},{"name":"Game","slug":"Game","permalink":"https://www.geminilight.cn/tags/Game/"},{"name":"Sentiment","slug":"Sentiment","permalink":"https://www.geminilight.cn/tags/Sentiment/"}]}